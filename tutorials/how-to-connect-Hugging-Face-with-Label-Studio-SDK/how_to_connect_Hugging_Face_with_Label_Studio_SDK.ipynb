{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBgzY9famCPX"
      },
      "source": [
        "**A Complete Guide to Connecting Hugging Face and Label Studio**\n",
        "\n",
        "This tutorial shows you how to create a seamless NLP workflow by integrating Hugging Face datasets and models with Label Studio for annotation and active learning.\n",
        "\n",
        "## üìö What You'll Learn:\n",
        "\n",
        "1. **HF ‚Üí LS**: Load datasets from Hugging Face into Label Studio for annotation\n",
        "2. **LS ‚Üí HF**: Export labeled data from Label Studio for model training\n",
        "3. **HF ‚Üí LS**: Connect Hugging Face models as ML backends for pre-annotations and active learning\n",
        "\n",
        "## üéØ Tutorial Use Case:\n",
        "\n",
        "We'll build a **Named Entity Recognition (NER)** annotation project using the WikiANN dataset and integrate pre-trained models for intelligent pre-labeling.\n",
        "\n",
        "## ‚úÖ Prerequisites:\n",
        "- Label Studio instance (local or cloud)\n",
        "- Hugging Face account with API token (optional for public models)\n",
        "- Basic understanding of NLP and NER tasks\n",
        "- Python 3.8+"
      ],
      "id": "IBgzY9famCPX"
    },
    {
      "cell_type": "markdown",
      "id": "79791a0b",
      "metadata": {
        "id": "79791a0b"
      },
      "source": [
        "---\n",
        "\n",
        "## üí° Why This Integration Matters\n",
        "\n",
        "Before we dive into the code, let's understand the value of connecting Hugging Face with Label Studio.\n",
        "\n",
        "This integration creates a powerful, automated ML workflow that transforms how you build and deploy NLP models.\n",
        "\n",
        "### üöÄ Key Benefits:\n",
        "\n",
        "#### 1. **Accelerated Annotation Workflow** ‚ö°\n",
        "- **10x faster labeling**: Pre-trained models provide initial annotations, reducing manual work by 60-80%\n",
        "- **Smart pre-labeling**: Models suggest entities, annotators only review and correct\n",
        "- **Focus on hard cases**: Spend time on uncertain predictions, not obvious labels\n",
        "\n",
        "#### 2. **Seamless Data Pipeline** üîÑ\n",
        "- **No manual data prep**: Direct import from Hugging Face datasets to Label Studio\n",
        "- **One-click export**: Labeled data automatically formatted for model training\n",
        "- **Zero data loss**: Perfect alignment between annotations and tokenization\n",
        "\n",
        "#### 3. **Continuous Model Improvement** üìà\n",
        "- **Active learning loop**: Label ‚Üí Train ‚Üí Predict ‚Üí Repeat\n",
        "- **Domain adaptation**: Fine-tune general models on your specific data\n",
        "- **Track progress**: Compare model versions and measure improvement over time\n",
        "\n",
        "#### 4. **Production-Ready ML** üè≠\n",
        "- **Reproducible workflows**: Automated pipelines eliminate manual steps\n",
        "- **Version control**: Track datasets, labels, and model versions together\n",
        "- **Scale effortlessly**: Process thousands of documents with batch predictions\n",
        "\n",
        "### üéØ Real-World Impact:\n",
        "\n",
        "**Typical improvements across annotation projects:**\n",
        "\n",
        "| Metric | Without Integration | With HF + Label Studio | Improvement |\n",
        "|--------|---------------------|------------------------|-------------|\n",
        "| Labeling speed | Baseline | 60-80% faster | ‚ö° 2-5x speedup |\n",
        "| Annotation accuracy | 90-95% | 98%+ | ‚úÖ Fewer errors |\n",
        "| Data preparation | Days of manual work | Minutes (automated) | ‚è±Ô∏è Massive time savings |\n",
        "| Model iteration | Static (train once) | Continuous improvement | üîÑ Active learning |\n",
        "| Workflow complexity | Multiple disconnected tools | Single integrated pipeline | üéØ Simplified workflow |\n",
        "\n",
        "### üìä Concrete Example:\n",
        "\n",
        "**Project**: Label 10,000 medical documents for entity extraction\n",
        "\n",
        "| Step | Traditional Approach | HF + Label Studio | Time Saved |\n",
        "|------|---------------------|-------------------|------------|\n",
        "| Data import | Manual download + formatting (8-10 hrs) | Automated import (5 min) | ~10 hrs |\n",
        "| Initial labeling | Label all 10,000 docs (500-600 hrs @ 3 min/doc) | Label 500 docs to bootstrap (25 hrs) | ‚Äî |\n",
        "| Model training | Train once at end | Train on 500 examples (1 hr) | ‚Äî |\n",
        "| Remaining labels | ‚Äî | Pre-annotate 9,500 docs (2 hrs)<br>Review/correct (95-140 hrs @ 45 sec/doc) | ~360 hrs |\n",
        "| **Total time** | **~530 hours** | **~130 hours** | **75% reduction** |\n",
        "| **Outcome** | Static model | Continuously improving model | ‚úÖ |\n",
        "\n",
        "### üåü Who Benefits Most:\n",
        "\n",
        "- **Data Scientists**: Faster experimentation and model iteration\n",
        "- **Annotation Teams**: Less tedious work, focus on quality\n",
        "- **ML Engineers**: Production-ready pipelines from day one\n",
        "- **Researchers**: Reproducible experiments and dataset management\n",
        "- **Startups**: Build high-quality labeled datasets on limited budgets\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to build this workflow?** Let's get started! üëá\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqKY25eZmCPa"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q label-studio-sdk datasets transformers torch huggingface_hub accelerate\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")"
      ],
      "id": "nqKY25eZmCPa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN8SYX-qmCPb"
      },
      "source": [
        "---\n",
        "\n",
        "## üîß Setup & Authentication\n",
        "\n",
        "### Step 1: Connect to Label Studio\n",
        "\n",
        "Set your environment variables before running:\n",
        "```bash\n",
        "export LABEL_STUDIO_URL=\"http://localhost:8080\"  # or your Label Studio URL\n",
        "export LABEL_STUDIO_API_KEY=\"your-api-key-here\"\n",
        "```\n",
        "\n",
        "To get your API key: Go to Label Studio ‚Üí Account & Settings ‚Üí Personal Access Token"
      ],
      "id": "IN8SYX-qmCPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc08ZUgImCPb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from label_studio_sdk import Client\n",
        "\n",
        "# Get credentials from environment variables\n",
        "ls_api_key = os.environ.get('LABEL_STUDIO_API_KEY')\n",
        "ls_url = os.environ.get('LABEL_STUDIO_URL', 'http://localhost:8080')\n",
        "\n",
        "if not ls_api_key:\n",
        "    raise ValueError('‚ùå Please set LABEL_STUDIO_API_KEY environment variable.')\n",
        "\n",
        "# Connect to Label Studio\n",
        "try:\n",
        "    ls = Client(url=ls_url, api_key=ls_api_key)\n",
        "    connection_status = ls.check_connection()\n",
        "    print(f'‚úÖ Connected to Label Studio at {ls_url}')\n",
        "    print(f'   Connection status: {connection_status}')\n",
        "except Exception as e:\n",
        "    raise ConnectionError(f'‚ùå Failed to connect to Label Studio: {str(e)}')"
      ],
      "id": "Xc08ZUgImCPb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBcBmNCnmCPb"
      },
      "source": [
        "### Step 2: Authenticate with Hugging Face\n",
        "\n",
        "Set your Hugging Face token:\n",
        "```bash\n",
        "export HF_TOKEN=\"your-hf-token-here\"\n",
        "```\n",
        "\n",
        "Get your token at: https://huggingface.co/settings/tokens"
      ],
      "id": "zBcBmNCnmCPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLjigfZ0mCPc"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Get Hugging Face token (optional but recommended for accessing private models)\n",
        "hf_token = os.environ.get('HF_TOKEN')\n",
        "\n",
        "if hf_token:\n",
        "    try:\n",
        "        login(token=hf_token)\n",
        "        print('‚úÖ Logged into Hugging Face Hub')\n",
        "    except Exception as e:\n",
        "        print(f'‚ö†Ô∏è  Warning: HF login failed: {str(e)}')\n",
        "        print('   Continuing with public models only...')\n",
        "else:\n",
        "    print('‚ÑπÔ∏è  No HF_TOKEN provided. Using public models only.')"
      ],
      "id": "gLjigfZ0mCPc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpVYmq08mCPc"
      },
      "source": [
        "---\n",
        "\n",
        "## üì• Part 1: Hugging Face ‚Üí Label Studio (Import Dataset)\n",
        "\n",
        "### Step 3: Create Label Studio Project\n",
        "\n",
        "We'll create a Named Entity Recognition project with labels for Person (PER), Organization (ORG), Location (LOC), and Miscellaneous (MISC) entities."
      ],
      "id": "PpVYmq08mCPc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHEIhzPMmCPc"
      },
      "outputs": [],
      "source": [
        "# Define Label Studio labeling configuration for NER\n",
        "ner_config = '''\n",
        "<View>\n",
        "  <Text name=\"text\" value=\"$text\"/>\n",
        "  <Labels name=\"ner\" toName=\"text\">\n",
        "    <Label value=\"PER\" background=\"#FF6B6B\"/>\n",
        "    <Label value=\"ORG\" background=\"#4ECDC4\"/>\n",
        "    <Label value=\"LOC\" background=\"#95E77D\"/>\n",
        "    <Label value=\"MISC\" background=\"#FFE66D\"/>\n",
        "  </Labels>\n",
        "</View>\n",
        "'''\n",
        "\n",
        "# Create project (or use existing one)\n",
        "project_title = 'Hugging Face + Label Studio NER Tutorial'\n",
        "project = ls.start_project(\n",
        "    title=project_title,\n",
        "    label_config=ner_config,\n",
        "    description='Tutorial: NER annotation with WikiANN dataset from HuggingFace'\n",
        ")\n",
        "\n",
        "print(f'‚úÖ Project created successfully!')\n",
        "print(f'   Project ID: {project.id}')\n",
        "print(f'   Project URL: {ls_url}/projects/{project.id}')"
      ],
      "id": "vHEIhzPMmCPc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9kyQ5uemCPd"
      },
      "source": [
        "We'll load the WikiANN dataset (a multilingual NER dataset) from Hugging Face. WikiANN provides high-quality NER annotations for English and 175+ other languages.\n",
        "\n",
        "**Why this matters:** Direct dataset import eliminates manual data preparation, ensures consistency, and makes it easy to update your annotation project with new data."
      ],
      "id": "N9kyQ5uemCPd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upvuLg4omCPd"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset from Hugging Face\n",
        "print('üì¶ Loading WikiANN dataset from Hugging Face...')\n",
        "dataset = load_dataset('wikiann', 'en', split='train[:100]')\n",
        "print(f'   Loaded {len(dataset)} examples')\n",
        "\n",
        "# Convert Hugging Face dataset format to Label Studio task format\n",
        "tasks = []\n",
        "for idx, row in enumerate(dataset):\n",
        "    # Join tokens into a single text string\n",
        "    text = ' '.join(row['tokens'])\n",
        "\n",
        "    # Create Label Studio task format\n",
        "    task = {\n",
        "        \"data\": {\n",
        "            \"text\": text\n",
        "        },\n",
        "        # Store original metadata for reference\n",
        "        \"meta\": {\n",
        "            \"source\": \"wikiann\",\n",
        "            \"hf_index\": idx\n",
        "        }\n",
        "    }\n",
        "    tasks.append(task)\n",
        "\n",
        "# Import tasks into Label Studio using SDK\n",
        "print(f'\\nüì§ Importing {len(tasks)} tasks into Label Studio...')\n",
        "project.import_tasks(tasks)\n",
        "\n",
        "# Verify import\n",
        "imported_tasks = project.get_tasks()\n",
        "print(f'‚úÖ Successfully imported {len(imported_tasks)} tasks!')\n",
        "print(f'\\nüìù Sample task:')\n",
        "print(f'   Text: {imported_tasks[0][\"data\"][\"text\"][:100]}...')"
      ],
      "id": "upvuLg4omCPd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5tUcLXImCPd"
      },
      "source": [
        "---\n",
        "\n",
        "## üì§ Part 2: Label Studio ‚Üí Hugging Face (Export & Train)\n",
        "\n",
        "### Step 5: Label Some Data (Manual Step)\n",
        "\n",
        "**‚ö†Ô∏è Action Required:** Before continuing, go to Label Studio and label a few tasks (at least 10-20 for meaningful training).\n",
        "\n",
        "1. Open your project: {ls_url}/projects/{project.id}\n",
        "2. Click on tasks and annotate entities (PER, ORG, LOC, MISC)\n",
        "3. Submit your annotations\n",
        "\n",
        "Once you've labeled some data, continue to the next cell.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 6: Export Annotations from Label Studio\n",
        "\n",
        "We'll export the labeled data and convert it to Hugging Face format for model training.\n",
        "\n",
        "**Why this matters:** This automated conversion saves hours of manual data preparation and ensures your annotations are correctly aligned with model tokenization."
      ],
      "id": "A5tUcLXImCPd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrfSYe_BmCPe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "\n",
        "# Export annotations from Label Studio using SDK\n",
        "print('üì• Exporting annotations from Label Studio...')\n",
        "ls_data = project.export_tasks(export_type='JSON')  # Already returns a list\n",
        "\n",
        "# Check how many tasks have annotations\n",
        "labeled_tasks = [task for task in ls_data if task.get('annotations')]\n",
        "print(f'   Total tasks: {len(ls_data)}')\n",
        "print(f'   Labeled tasks: {len(labeled_tasks)}')\n",
        "\n",
        "if len(labeled_tasks) < 5:\n",
        "    print('\\n‚ö†Ô∏è  Warning: Very few labeled tasks. Results may not be meaningful.')\n",
        "    print('   Consider labeling more data in Label Studio before training.')\n",
        "\n",
        "# Initialize tokenizer (using BERT for NER)\n",
        "print('\\nüî§ Loading tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased', use_fast=True)\n",
        "\n",
        "# Define NER label schema (BIO format)\n",
        "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "label_to_id = {label: idx for idx, label in enumerate(label_list)}\n",
        "print(f'   Label schema: {label_list}')\n",
        "\n",
        "# Convert Label Studio annotations to HuggingFace format\n",
        "print('\\nüîÑ Converting annotations to HuggingFace format...')\n",
        "\n",
        "texts = [task['data']['text'] for task in ls_data]\n",
        "tokenized = tokenizer(texts, return_offsets_mapping=True, truncation=True, padding=True)\n",
        "\n",
        "all_labels = []\n",
        "for i, task in enumerate(ls_data):\n",
        "    offsets = tokenized['offset_mapping'][i]\n",
        "\n",
        "    # Extract entity spans from Label Studio annotations\n",
        "    spans = []\n",
        "    annotations = task.get('annotations', [])\n",
        "    if annotations:\n",
        "        # Use the first annotation (or implement logic for multiple annotations)\n",
        "        results = annotations[0].get('result', [])\n",
        "        for result in results:\n",
        "            if result.get('type') == 'labels':\n",
        "                value = result['value']\n",
        "                spans.append((\n",
        "                    value['start'],\n",
        "                    value['end'],\n",
        "                    value['labels'][0]\n",
        "                ))\n",
        "\n",
        "    # Align spans with tokenized output (handle tokenization offsets)\n",
        "    token_labels = []\n",
        "    for token_start, token_end in offsets:\n",
        "        # Special tokens (CLS, SEP, PAD) have start==end\n",
        "        if token_start == token_end:\n",
        "            token_labels.append(-100)  # Ignore in loss calculation\n",
        "            continue\n",
        "\n",
        "        # Find if this token overlaps with any entity span\n",
        "        label = 'O'  # Default: Outside any entity\n",
        "        for span_start, span_end, span_label in spans:\n",
        "            # Check if token overlaps with span\n",
        "            if token_end <= span_start or token_start >= span_end:\n",
        "                continue  # No overlap\n",
        "\n",
        "            # Determine if this is the beginning of an entity or inside\n",
        "            if token_start == span_start:\n",
        "                label = f'B-{span_label}'  # Beginning of entity\n",
        "            else:\n",
        "                label = f'I-{span_label}'  # Inside entity\n",
        "            break\n",
        "\n",
        "        token_labels.append(label_to_id[label])\n",
        "\n",
        "    all_labels.append(token_labels)\n",
        "\n",
        "# Create HuggingFace Dataset\n",
        "hf_dataset = Dataset.from_dict({\n",
        "    \"input_ids\": tokenized['input_ids'],\n",
        "    \"attention_mask\": tokenized['attention_mask'],\n",
        "    \"labels\": all_labels\n",
        "})\n",
        "\n",
        "print(f'‚úÖ Conversion complete!')\n",
        "print(f'   Dataset size: {len(hf_dataset)} examples')\n",
        "print(f'\\nüìù Sample (first example):')\n",
        "print(f'   Input IDs shape: {len(hf_dataset[0][\"input_ids\"])}')\n",
        "print(f'   Labels shape: {len(hf_dataset[0][\"labels\"])}')\n",
        "print(f'   Sample tokens: {tokenizer.convert_ids_to_tokens(hf_dataset[0][\"input_ids\"][:20])}')"
      ],
      "id": "lrfSYe_BmCPe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Eqvs5VymCPe"
      },
      "source": [
        "### Step 7 (Optional): Train Hugging Face Model\n",
        "\n",
        "**Note:** This step demonstrates training a custom model. You can skip this and jump to Part 3 to use pre-trained models instead.\n",
        "\n",
        "**Why train:** Fine-tuning on your labeled data creates domain-specific models that outperform general models on your specific use case."
      ],
      "id": "2Eqvs5VymCPe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqVuMjc6mCPe"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Only train if we have enough labeled data\n",
        "if len(labeled_tasks) < 10:\n",
        "    print('‚ö†Ô∏è  Skipping training: Need at least 10 labeled examples.')\n",
        "    print('   Label more data in Label Studio, then re-run this cell.')\n",
        "else:\n",
        "    print('üöÄ Starting model training...')\n",
        "\n",
        "    # Initialize model\n",
        "    num_labels = len(label_list)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        'bert-base-cased',\n",
        "        num_labels=num_labels,\n",
        "        id2label={i: label for i, label in enumerate(label_list)},\n",
        "        label2id=label_to_id\n",
        "    )\n",
        "\n",
        "    # Split into train/validation\n",
        "    splits = hf_dataset.train_test_split(test_size=0.15, seed=42)\n",
        "    train_dataset = splits['train']\n",
        "    eval_dataset = splits['test']\n",
        "    print(f'   Train set: {len(train_dataset)} examples')\n",
        "    print(f'   Eval set: {len(eval_dataset)} examples')\n",
        "\n",
        "    # Data collator handles padding\n",
        "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./ner_model',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        learning_rate=5e-5,\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        save_total_limit=2,\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=False,  # Set to True to push to HuggingFace Hub\n",
        "    )\n",
        "\n",
        "    # Simple metrics function\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "        # Remove ignored index (special tokens)\n",
        "        true_predictions = [\n",
        "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "        true_labels = [\n",
        "            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "\n",
        "        # Simple accuracy\n",
        "        all_preds = [p for pred_list in true_predictions for p in pred_list]\n",
        "        all_labels = [l for label_list in true_labels for l in label_list]\n",
        "        accuracy = sum([p == l for p, l in zip(all_preds, all_labels)]) / len(all_labels)\n",
        "\n",
        "        return {\"accuracy\": accuracy}\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train!\n",
        "    print('\\nüìö Training in progress...')\n",
        "    train_result = trainer.train()\n",
        "\n",
        "    print('\\n‚úÖ Training complete!')\n",
        "    print(f'   Final loss: {train_result.training_loss:.4f}')\n",
        "\n",
        "    # Save the model\n",
        "    trainer.save_model('./ner_model_final')\n",
        "    print('üíæ Model saved to ./ner_model_final')"
      ],
      "id": "SqVuMjc6mCPe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XJKkI8umCPe"
      },
      "source": [
        "---\n",
        "\n",
        "## ü§ñ Part 3: Hugging Face ‚Üí Label Studio (ML Backend Integration)\n",
        "\n",
        "### Step 8: Create ML Backend with Hugging Face Model\n",
        "\n",
        "Now we'll connect a Hugging Face model as an ML backend to provide pre-annotations in Label Studio. This dramatically speeds up the annotation process!\n",
        "\n",
        "**Benefits:**\n",
        "- **Pre-annotations**: Model generates initial predictions for annotators to review\n",
        "- **Active Learning**: Focus annotation efforts on difficult/uncertain examples\n",
        "- **Continuous Improvement**: Retrain model with new labels, deploy updated predictions\n",
        "\n",
        "We'll use a pre-trained NER model from Hugging Face. You can also use your custom trained model from Step 7."
      ],
      "id": "9XJKkI8umCPe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdiHQ70qmCPf"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import time\n",
        "\n",
        "# Load a pre-trained Hugging Face NER model\n",
        "print('ü§ó Loading Hugging Face NER model...')\n",
        "# Using a popular pre-trained NER model\n",
        "ner_pipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=\"dslim/bert-base-NER\",\n",
        "    aggregation_strategy=\"simple\"  # Combines B- and I- tags\n",
        ")\n",
        "print('‚úÖ Model loaded successfully!')\n",
        "\n",
        "# Map Hugging Face labels to our Label Studio labels\n",
        "LABEL_MAPPING = {\n",
        "    'PER': 'PER',\n",
        "    'ORG': 'ORG',\n",
        "    'LOC': 'LOC',\n",
        "    'MISC': 'MISC'\n",
        "}\n",
        "\n",
        "def create_predictions_for_task(task):\n",
        "    \"\"\"Generate predictions for a single Label Studio task\"\"\"\n",
        "    text = task['data']['text']\n",
        "\n",
        "    # Get predictions from Hugging Face model\n",
        "    entities = ner_pipeline(text)\n",
        "\n",
        "    # Convert to Label Studio format\n",
        "    results = []\n",
        "    for entity in entities:\n",
        "        # Map label if needed\n",
        "        label = LABEL_MAPPING.get(entity['entity_group'], 'MISC')\n",
        "\n",
        "        result = {\n",
        "            \"from_name\": \"ner\",\n",
        "            \"to_name\": \"text\",\n",
        "            \"type\": \"labels\",\n",
        "            \"value\": {\n",
        "                \"start\": entity['start'],\n",
        "                \"end\": entity['end'],\n",
        "                \"text\": text[entity['start']:entity['end']],\n",
        "                \"labels\": [label]\n",
        "            },\n",
        "            \"score\": entity['score']  # Confidence score\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test the prediction function with a sample\n",
        "print('\\nüß™ Testing prediction function...')\n",
        "sample_text = \"Apple Inc. was founded by Steve Jobs in California.\"\n",
        "test_task = {\"data\": {\"text\": sample_text}}\n",
        "\n",
        "predictions = create_predictions_for_task(test_task)\n",
        "print(f'   Input: \"{sample_text}\"')\n",
        "print(f'   Found {len(predictions)} entities:')\n",
        "for pred in predictions:\n",
        "    entity_text = pred['value']['text']\n",
        "    entity_label = pred['value']['labels'][0]\n",
        "    entity_score = pred['score']\n",
        "    print(f'     - \"{entity_text}\" ‚Üí {entity_label} (confidence: {entity_score:.2f})')"
      ],
      "id": "EdiHQ70qmCPf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C08ffOrDmCPf"
      },
      "source": [
        "### Step 9: Generate Pre-annotations\n",
        "\n",
        "Now let's use our Hugging Face model to generate predictions for unlabeled tasks in Label Studio!"
      ],
      "id": "C08ffOrDmCPf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c200028",
      "metadata": {
        "id": "0c200028"
      },
      "outputs": [],
      "source": [
        "# Get unlabeled tasks from Label Studio\n",
        "print('üìã Fetching unlabeled tasks...')\n",
        "all_tasks = project.get_tasks()\n",
        "unlabeled_tasks = [task for task in all_tasks if not task.get('annotations')]\n",
        "\n",
        "print(f'   Total tasks: {len(all_tasks)}')\n",
        "print(f'   Unlabeled tasks: {len(unlabeled_tasks)}')\n",
        "\n",
        "if len(unlabeled_tasks) == 0:\n",
        "    print('\\n‚úÖ All tasks are already labeled! No predictions needed.')\n",
        "else:\n",
        "    # Generate predictions for unlabeled tasks\n",
        "    print(f'\\nüîÆ Generating predictions for {min(10, len(unlabeled_tasks))} tasks...')\n",
        "\n",
        "    prediction_count = 0\n",
        "    for task in unlabeled_tasks[:10]:  # Start with first 10 for demo\n",
        "        try:\n",
        "            # Generate predictions using our HuggingFace model\n",
        "            results = create_predictions_for_task(task)\n",
        "\n",
        "            # Create prediction in Label Studio using SDK\n",
        "            project.create_prediction(\n",
        "                task_id=task['id'],\n",
        "                result=results,\n",
        "                model_version='huggingface-bert-base-NER'\n",
        "            )\n",
        "\n",
        "            prediction_count += 1\n",
        "\n",
        "            # Show progress\n",
        "            if prediction_count % 5 == 0:\n",
        "                print(f'   Generated {prediction_count} predictions...')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'   ‚ö†Ô∏è  Error on task {task[\"id\"]}: {str(e)}')\n",
        "            continue\n",
        "\n",
        "    print(f'\\n‚úÖ Successfully created {prediction_count} pre-annotations!')\n",
        "    print(f'\\nüí° Next steps:')\n",
        "    print(f'   1. Open Label Studio: {ls_url}/projects/{project.id}')\n",
        "    print(f'   2. Review and correct the pre-annotations')\n",
        "    print(f'   3. Submit your annotations')\n",
        "    print(f'   4. Export and retrain for continuous improvement!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4037e9",
      "metadata": {
        "id": "4e4037e9"
      },
      "source": [
        "---\n",
        "\n",
        "## üéâ Summary & Next Steps\n",
        "\n",
        "Congratulations! You've built a complete Hugging Face + Label Studio integration pipeline for Named Entity Recognition!\n",
        "\n",
        "### What You Accomplished:\n",
        "\n",
        "‚úÖ **HF ‚Üí LS**: Loaded WikiANN dataset from Hugging Face into Label Studio  \n",
        "‚úÖ **LS ‚Üí HF**: Exported labeled data and converted to Hugging Face format with token alignment  \n",
        "‚úÖ **HF ‚Üí LS**: Generated pre-annotations using Hugging Face NER models  \n",
        "‚úÖ **Trained**: Fine-tuned a custom NER model on your labeled data\n",
        "\n",
        "### The Complete Workflow:\n",
        "\n",
        "```\n",
        "1. Import data from Hugging Face ‚Üí Label Studio\n",
        "2. Annotate tasks in Label Studio (with ML assistance)\n",
        "3. Export annotations ‚Üí Train/fine-tune Hugging Face model  \n",
        "4. Deploy updated model ‚Üí Generate better predictions\n",
        "5. Repeat for continuous improvement! üîÑ\n",
        "```\n",
        "\n",
        "### üîÑ Apply to Other Tasks:\n",
        "\n",
        "Want to adapt this workflow for other tasks? Check out:\n",
        "- **Text Classification**: Adapt the export/prediction logic for sentiment analysis, topic classification, etc.\n",
        "- **Question Answering**: Modify for extractive or generative QA tasks\n",
        "- **Summarization**: Apply to text summarization workflows\n",
        "\n",
        "### Advanced Use Cases:\n",
        "\n",
        "- **Active Learning**: Use model confidence scores to prioritize uncertain examples for annotation\n",
        "- **Domain Adaptation**: Fine-tune on your specific domain data for better performance\n",
        "- **Multi-annotator**: Combine predictions from multiple models or annotators\n",
        "- **Batch Processing**: Process large datasets efficiently with batch predictions\n",
        "- **Model Versioning**: Track model versions and compare performance over time\n",
        "\n",
        "### Resources:\n",
        "\n",
        "- üìñ [Label Studio SDK Documentation](https://labelstud.io/sdk/)\n",
        "- ü§ó [HuggingFace Transformers](https://huggingface.co/docs/transformers)\n",
        "- üéØ [Label Studio ML Backend](https://github.com/HumanSignal/label-studio-ml-backend)\n",
        "\n",
        "### Need Help?\n",
        "\n",
        "- Label Studio Community: https://slack.labelstudio.heartex.com/\n",
        "- HuggingFace Forums: https://discuss.huggingface.co/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c66c4650",
      "metadata": {
        "id": "c66c4650"
      },
      "source": [
        "---\n",
        "\n",
        "## üöÄ Next steps: Production ML Backend Setup\n",
        "\n",
        "For production use, you'll want to deploy your Hugging Face model as a persistent ML backend server. Here's how:\n",
        "\n",
        "### Option 1: Using Label Studio ML Backend (Recommended for Production)\n",
        "\n",
        "```bash\n",
        "# Install label-studio-ml\n",
        "pip install label-studio-ml\n",
        "\n",
        "# Create a new ML backend project\n",
        "label-studio-ml init my_ner_backend --script label_studio_ml/examples/simple_text_classifier.py\n",
        "\n",
        "# Edit my_ner_backend/model.py to use your Hugging Face model\n",
        "# Then start the server:\n",
        "label-studio-ml start my_ner_backend --port 9090\n",
        "```\n",
        "\n",
        "Then connect it in Label Studio:\n",
        "1. Go to Project Settings ‚Üí Machine Learning\n",
        "2. Click \"Add Model\"\n",
        "3. Enter URL: `http://localhost:9090`\n",
        "4. Enable \"Use for interactive preannotations\"\n",
        "\n",
        "### Option 2: Direct SDK Predictions (This Tutorial)\n",
        "\n",
        "The approach used in this tutorial (SDK's `create_prediction()`) is perfect for:\n",
        "- Batch processing of large datasets\n",
        "- One-time pre-annotation runs\n",
        "- Jupyter notebooks and data science workflows\n",
        "- Prototyping and experimentation\n",
        "\n",
        "### When to Use Each:\n",
        "\n",
        "| Feature | SDK Predictions | ML Backend Server |\n",
        "|---------|----------------|-------------------|\n",
        "| Real-time predictions | ‚ùå | ‚úÖ |\n",
        "| Interactive labeling | ‚ùå | ‚úÖ |\n",
        "| Batch processing | ‚úÖ | ‚úÖ |\n",
        "| Easy setup | ‚úÖ | ‚ö†Ô∏è Moderate |\n",
        "| Production ready | ‚ö†Ô∏è | ‚úÖ |\n",
        "\n",
        "Choose based on your use case!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}