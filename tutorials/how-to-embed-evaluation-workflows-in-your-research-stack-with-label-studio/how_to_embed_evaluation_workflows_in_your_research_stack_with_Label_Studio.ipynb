{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Label Studio Requirements\n",
        "\n",
        "This tutorial showcases one or more features available only in Label Studio Enterprise. We recommend [connecting with our team](https://humansignal.com/contact-sales/) to request a trial or to enable them in your account."
      ],
      "metadata": {
        "id": "hyMuXvqJQI90"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEVBSt8z-gI6"
      },
      "source": [
        "## The Context-Switching Tax\n",
        "\n",
        "You're deep in a Jupyter notebook, fine-tuning a medical LLM. Results look promising, but you need human evaluation before shipping.\n",
        "\n",
        "The usual drill: export outputs to CSV, upload to evaluation platform, assign tasks, wait for results, download CSV, merge back with your data, re-import to notebook for analysis. By then, you've lost your flow state.\n",
        "\n",
        "**What if evaluation lived in your notebook?** No exports. No context switches. Just evaluate, analyze, iterate.\n",
        "\n",
        "## What We're Building\n",
        "\n",
        "Over the next 15-20 minutes, you'll build an embedded evaluation workflow that:\n",
        "\n",
        "1. **Loads real medical Q&A data** from Hugging Face (100 tasks)\n",
        "2. **Creates a structured evaluation interface** with custom criteria\n",
        "3. **Embeds Label Studio directly in this notebook** for zero-context-switch evaluation\n",
        "4. **Exports to pandas** for instant analysis and visualization\n",
        "5. **Generates insights** about model performance across medical specialties\n",
        "\n",
        "**Real-world scenario**: You're evaluating GPT-5's responses to patient medical questions. You need domain experts to rate accuracy, safety, completeness, and helpfulness‚Äîthen immediately analyze patterns to inform the next training iteration.\n",
        "\n",
        "By the end, you'll have a template you can adapt for any evaluation workflow: content moderation, prompt testing, data quality checks, or model comparison studies.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Requirements & Roles\n",
        "\n",
        "This tutorial has two parts:\n",
        "\n",
        "### üë§ **Part 1: Admin Setup (One-Time, ~5 minutes)**\n",
        "Your Label Studio **Owner/Admin** needs to:\n",
        "- Enable embedding for your organization ([request access](https://humansignal.com/contact-sales/))\n",
        "- Run Part 1 to generate keys and configure organization\n",
        "- **Share the private key** with ML engineers (via secure channel)\n",
        "\n",
        "**Credentials needed:**\n",
        "- `LABEL_STUDIO_API_KEY` - Admin/Owner API token\n",
        "- `LABEL_STUDIO_URL` - Your LSE instance URL\n",
        "\n",
        "### üî¨ **Part 2: ML Engineer Workflow (~15 minutes)**\n",
        "Any team member can run Part 2 repeatedly with:\n",
        "- `LABEL_STUDIO_API_KEY` - Your personal API token (any role)\n",
        "- `LABEL_STUDIO_URL` - Your LSE instance URL  \n",
        "- `EMBED_PRIVATE_KEY` - Private key shared by admin (from Part 1)\n",
        "\n",
        "**If you're an admin**: Run both parts end-to-end.  \n",
        "**If you're an ML engineer**: Get the private key from your admin, set all three env vars, then skip to Part 2.\n",
        "\n",
        "**How to set credentials:**\n",
        "- **Colab**: Click üîë ‚Üí Add secrets ‚Üí Toggle \"Notebook access\" ON\n",
        "- **Local Jupyter**: `export LABEL_STUDIO_API_KEY=\"...\" EMBED_PRIVATE_KEY=\"...\"`\n",
        "\n",
        "Let's get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOmKdKGK-gI7"
      },
      "source": [
        "# üõ†Ô∏è Setup (Required for Everyone)\n",
        "\n",
        "Whether you're an admin or ML engineer, run these cells first to install dependencies and configure credentials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_KD8UY6-gI7"
      },
      "outputs": [],
      "source": [
        "# Install what we need\n",
        "%pip install -q label-studio-sdk pandas matplotlib seaborn cryptography PyJWT datasets requests python-dotenv\n",
        "\n",
        "# Import everything\n",
        "import os, json, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import jwt, base64, time\n",
        "from cryptography.hazmat.primitives import serialization\n",
        "from cryptography.hazmat.primitives.asymmetric import rsa\n",
        "from IPython.display import HTML, display, Markdown\n",
        "from label_studio_sdk.client import LabelStudio\n",
        "from datasets import load_dataset\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2rbqEyL-gI8"
      },
      "source": [
        "## üîê Configure Credentials\n",
        "\n",
        "Set your environment variables based on your role:\n",
        "\n",
        "**üë§ Admins (running Part 1 + 2):**\n",
        "```bash\n",
        "export LABEL_STUDIO_API_KEY=\"your_admin_token\"\n",
        "export LABEL_STUDIO_URL=\"https://app.humansignal.com\"\n",
        "```\n",
        "\n",
        "**üî¨ ML Engineers (running Part 2 only):**\n",
        "```bash\n",
        "export LABEL_STUDIO_API_KEY=\"your_personal_token\"\n",
        "export LABEL_STUDIO_URL=\"https://app.humansignal.com\"\n",
        "export EMBED_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\"\n",
        "```\n",
        "\n",
        "**Using Google Colab?**  \n",
        "Click the üîë icon in the sidebar ‚Üí Add secrets ‚Üí Toggle \"Notebook access\" ON for each\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwCxwwVU-gI8"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv\n",
        "\n",
        "# Load configuration with Google Colab Secrets support + fallback\n",
        "IS_GOOGLE_COLAB = False\n",
        "\n",
        "# Load from .env file if available (for local development)\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except:\n",
        "    pass  # dotenv not installed, will use system env vars\n",
        "\n",
        "def get_credential(key, default=None):\n",
        "    global IS_GOOGLE_COLAB\n",
        "    \"\"\"Get credential from Colab Secrets first, then environment variables\"\"\"\n",
        "    try:\n",
        "        # Try Google Colab Secrets first (most secure)\n",
        "        from google.colab import userdata\n",
        "        IS_GOOGLE_COLAB = True\n",
        "        return userdata.get(key)\n",
        "    except:\n",
        "        from os import environ\n",
        "        IS_GOOGLE_COLAB = False\n",
        "        # Fallback to environment variables (for local Jupyter)\n",
        "        return environ.get(key, default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L45m2_bP-gI8"
      },
      "outputs": [],
      "source": [
        "LABEL_STUDIO_URL = get_credential('LABEL_STUDIO_URL', 'https://app.humansignal.com')\n",
        "API_KEY = get_credential('LABEL_STUDIO_API_KEY')\n",
        "\n",
        "# Validate required credentials\n",
        "missing_vars = []\n",
        "if not API_KEY:\n",
        "    missing_vars.append('LABEL_STUDIO_API_KEY')\n",
        "\n",
        "if missing_vars:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #f8d7da; color: #856404; border: 1px solid #f5c6cb; border-radius: 5px;\">\n",
        "        <strong>‚ùå Missing Credentials</strong><br>\n",
        "        Please set your credentials using one of these methods:<br><br>\n",
        "\n",
        "        <strong>üîí Google Colab (Recommended):</strong><br>\n",
        "        1. Click the üîë key icon in the left sidebar<br>\n",
        "        2. Add secret: <code>LABEL_STUDIO_API_KEY</code><br>\n",
        "        3. Toggle \"Notebook access\" ON for the secret<br><br>\n",
        "\n",
        "        <strong>üíª Local Jupyter:</strong><br>\n",
        "        <code>\n",
        "        export LABEL_STUDIO_API_KEY=\"your_admin_api_key_here\"\n",
        "        </code><br><br>\n",
        "\n",
        "        <strong>Missing:</strong> {', '.join(missing_vars)}<br>\n",
        "        <small><strong>Why Colab Secrets?</strong> More secure than environment variables, encrypted storage, no code exposure</small>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "else:\n",
        "    # Determine which method was used\n",
        "    method = \"Google Colab Secrets\" if IS_GOOGLE_COLAB else \"Environment Variables\"\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "        <strong>‚úÖ Credentials Loaded</strong><br>\n",
        "        ‚Ä¢ Method: {method}<br>\n",
        "        ‚Ä¢ URL: {LABEL_STUDIO_URL}<br>\n",
        "        ‚Ä¢ API Key: {'*' * (len(API_KEY) - 4) + API_KEY[-4:] if len(API_KEY) > 4 else '****'}\n",
        "    </div>\n",
        "    \"\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOKUnRm3-gI8"
      },
      "source": [
        "---\n",
        "\n",
        "# üë§ Part 1: Admin Setup (One-Time Configuration)\n",
        "\n",
        "**üëã ML Engineers**: If your admin already configured embedding, **skip to Part 2** below.\n",
        "\n",
        "**üëã Admins**: This 5-minute setup enables your entire team to embed Label Studio in notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvphsDBX-gI8"
      },
      "source": [
        "**üë§ ADMIN ONLY - Run Once**: Generate keys and configure your organization for embedding.\n",
        "\n",
        "After running this cell:\n",
        "1. **Copy the private key** using the button below\n",
        "2. **Store it securely** (password manager, secrets vault, etc.)\n",
        "3. **Share with your team** so they can set `EMBED_PRIVATE_KEY` in their environment\n",
        "\n",
        "**üî¨ ML ENGINEERS**: If you already have the `EMBED_PRIVATE_KEY` from your admin, skip to **Part 2** below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85gVWfXy-gI8"
      },
      "outputs": [],
      "source": [
        "def generate_rsa_key_pair():\n",
        "    \"\"\"Generate a new RSA key pair for JWT signing\"\"\"\n",
        "    private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
        "    private_pem = private_key.private_bytes(\n",
        "        encoding=serialization.Encoding.PEM,\n",
        "        format=serialization.PrivateFormat.PKCS8,\n",
        "        encryption_algorithm=serialization.NoEncryption()\n",
        "    )\n",
        "    public_pem = private_key.public_key().public_bytes(\n",
        "        encoding=serialization.Encoding.PEM,\n",
        "        format=serialization.PublicFormat.SubjectPublicKeyInfo\n",
        "    )\n",
        "    return private_pem, public_pem, base64.b64encode(public_pem).decode('utf-8')\n",
        "\n",
        "def configure_embed_settings(ls_client, public_key_b64, organization_id):\n",
        "    \"\"\"Configure organization embedding settings (requires Owner role)\"\"\"\n",
        "    try:\n",
        "        embed_settings = {\n",
        "            \"public_verify_key\": public_key_b64,\n",
        "            \"public_verify_alg\": [\"RS256\"]\n",
        "        }\n",
        "\n",
        "        embed_domains = [\n",
        "            {\"domain\": \"colab.research.google.com\"},\n",
        "            {\"domain\": \"localhost\"},\n",
        "            {\"domain\": \"127.0.0.1\"},\n",
        "        ]\n",
        "\n",
        "        ls_client.organizations.update(\n",
        "            id=organization_id,\n",
        "            embed_settings=embed_settings,\n",
        "            embed_domains=embed_domains\n",
        "        )\n",
        "\n",
        "        return True, \"Embedding configured successfully\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, f\"Configuration failed: {str(e)}\"\n",
        "\n",
        "# ADMIN ONLY: Generate new key pair and configure organization\n",
        "# This creates a NEW private key - only do this once!\n",
        "private_key_pem, public_key_pem, public_key_b64 = generate_rsa_key_pair()\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<div style=\"padding: 15px; background: #e7f3ff; color: #004085; border: 1px solid #b8daff; border-radius: 5px; margin: 10px 0;\">\n",
        "    <strong>üîë Generating secure keys...</strong>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "# Get current user and organization info\n",
        "try:\n",
        "    from label_studio_sdk.client import LabelStudio\n",
        "    ls = LabelStudio(base_url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
        "    current_user = ls.users.whoami()\n",
        "    user_email = current_user.email\n",
        "    organization_id = current_user.active_organization\n",
        "\n",
        "    # Configure organization with the public key\n",
        "    success, message = configure_embed_settings(ls, public_key_b64, organization_id)\n",
        "\n",
        "    if success:\n",
        "        # Display success with copy-to-clipboard button for private key\n",
        "        private_key_str = private_key_pem.decode('utf-8')\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "            <strong>‚úÖ Organization configured for embedding!</strong><br><br>\n",
        "\n",
        "            <strong>üìã ADMIN: Save this private key for your team</strong><br>\n",
        "            <div style=\"background: #f8f9fa; padding: 10px; border-radius: 5px; margin: 10px 0; font-family: monospace; font-size: 11px; max-height: 150px; overflow-y: auto; white-space: pre-wrap; word-break: break-all;\">\n",
        "{private_key_str}</div>\n",
        "\n",
        "            <button onclick=\"navigator.clipboard.writeText(`{private_key_str}`).then(() => {{\n",
        "                this.textContent = '‚úÖ Copied!';\n",
        "                setTimeout(() => this.textContent = 'üìã Copy Private Key', 2000);\n",
        "            }})\" style=\"padding: 8px 15px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: bold; margin: 5px 0;\">\n",
        "                üìã Copy Private Key\n",
        "            </button>\n",
        "\n",
        "            <br><br>\n",
        "            <strong>‚ö†Ô∏è Next steps for your team:</strong><br>\n",
        "            1. Store this private key securely (password manager, secrets vault)<br>\n",
        "            2. Share it with ML engineers who will use embedding<br>\n",
        "            3. They should set: <code>export EMBED_PRIVATE_KEY=\"&lt;key_above&gt;\"</code><br>\n",
        "            4. Configuration applied to organization: {organization_id}\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "    else:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"padding: 15px; background: #f8d7da; color: #856404; border: 1px solid #f5c6cb; border-radius: 5px;\">\n",
        "            <strong>‚ùå Configuration failed</strong><br>\n",
        "            {message}<br><br>\n",
        "            This usually means you need Owner role permissions.<br>\n",
        "            Contact your Label Studio admin to configure embedding.\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "except Exception as e:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #f8d7da; color: #856404; border: 1px solid #f5c6cb; border-radius: 5px;\">\n",
        "        <strong>‚ùå Error:</strong> {str(e)}\n",
        "    </div>\n",
        "    \"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I61-ukSd-gI8"
      },
      "source": [
        "---\n",
        "\n",
        "# üî¨ Part 2: ML Engineer Workflow\n",
        "\n",
        "**This is the main workflow.** Once your admin has configured embedding (Part 1), you can run this section repeatedly for any evaluation project.\n",
        "\n",
        "**What you need:**\n",
        "- Your personal Label Studio API token (not admin required)\n",
        "- Access to your Label Studio Enterprise instance\n",
        "- This takes ~15 minutes first time, ~5 minutes for subsequent projects\n",
        "\n",
        "## Connect to Label Studio\n",
        "\n",
        "Set your credentials and connect:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMMu8z2q-gI8"
      },
      "source": [
        "**üî¨ ML ENGINEERS START HERE**: This cell generates your embed token using the private key.\n",
        "\n",
        "Make sure you have `EMBED_PRIVATE_KEY` set (get it from your admin who ran Part 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41nmZwLJ-gI8"
      },
      "outputs": [],
      "source": [
        "# ML ENGINEERS: Generate embed token using private key from environment\n",
        "# This works whether you're an admin running the full notebook OR an ML engineer with the shared key\n",
        "\n",
        "def generate_embed_token(user_email, organization_id, private_key_pem, expires_in_hours=24):\n",
        "    \"\"\"Generate JWT token for embedding authentication\"\"\"\n",
        "    payload = {\n",
        "        'user_email': user_email,\n",
        "        'organization_id': str(organization_id),\n",
        "        'embed_context': 'app',  # For notebook usage (VSCode/Cursor/Colab)\n",
        "        'iat': datetime.utcnow(),\n",
        "        'exp': datetime.utcnow() + timedelta(hours=expires_in_hours)\n",
        "    }\n",
        "    return jwt.encode(payload, private_key_pem, algorithm='RS256')\n",
        "\n",
        "# Check if we have a private key (either from Part 1 or from environment)\n",
        "EMBED_PRIVATE_KEY = get_credential('EMBED_PRIVATE_KEY')\n",
        "\n",
        "if not EMBED_PRIVATE_KEY:\n",
        "    # If no private key in environment, check if we just generated one in Part 1\n",
        "    try:\n",
        "        # If admin ran Part 1, private_key_pem will exist from that cell\n",
        "        if 'private_key_pem' not in locals():\n",
        "            raise NameError(\"private_key_pem not found\")\n",
        "        EMBED_PRIVATE_KEY = private_key_pem.decode('utf-8') if isinstance(private_key_pem, bytes) else private_key_pem\n",
        "    except NameError:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"padding: 15px; background: #fff3cd; color: #856404; border: 1px solid #ffeaa7; border-radius: 5px;\">\n",
        "            <strong>‚ö†Ô∏è Private key not found</strong><br><br>\n",
        "\n",
        "            <strong>Option 1 - ML Engineers (recommended):</strong><br>\n",
        "            Get the private key from your admin and set:<br>\n",
        "            <code>export EMBED_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\\\n...\\\\n-----END PRIVATE KEY-----\"</code><br><br>\n",
        "\n",
        "            <strong>Option 2 - Admins:</strong><br>\n",
        "            Run <strong>Part 1</strong> above to generate keys and configure your organization.<br><br>\n",
        "\n",
        "            Then re-run this cell.\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "        raise Exception(\"EMBED_PRIVATE_KEY not found. Please set it or run Part 1 first.\")\n",
        "\n",
        "# Convert string key to bytes if needed\n",
        "if isinstance(EMBED_PRIVATE_KEY, str):\n",
        "    private_key_bytes = EMBED_PRIVATE_KEY.encode('utf-8')\n",
        "else:\n",
        "    private_key_bytes = EMBED_PRIVATE_KEY\n",
        "\n",
        "# Connect to Label Studio and generate embed token\n",
        "try:\n",
        "    from label_studio_sdk.client import LabelStudio\n",
        "    ls = LabelStudio(base_url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
        "\n",
        "    # Get current user information\n",
        "    current_user = ls.users.whoami()\n",
        "    user_email = current_user.email\n",
        "    organization_id = current_user.active_organization\n",
        "\n",
        "    if not organization_id:\n",
        "        raise Exception(\"Could not determine organization ID. Please ensure you're a member of an organization.\")\n",
        "    if not user_email:\n",
        "        raise Exception(\"Could not determine user email. Please check your API key permissions.\")\n",
        "\n",
        "    # Generate embed token for this user\n",
        "    embed_token = generate_embed_token(user_email, organization_id, private_key_bytes)\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "        <strong>‚úÖ Ready to embed!</strong><br>\n",
        "        ‚Ä¢ Connected as: {user_email}<br>\n",
        "        ‚Ä¢ Organization: {organization_id}<br>\n",
        "        ‚Ä¢ Embed token: Generated (valid for 24 hours)<br>\n",
        "        ‚Ä¢ You can now create projects and embed evaluation interfaces\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "except Exception as e:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #f8d7da; color: #856404; border: 1px solid #f5c6cb; border-radius: 5px;\">\n",
        "        <strong>‚ùå Connection failed</strong><br>\n",
        "        {str(e)}<br><br>\n",
        "        <strong>Common issues:</strong><br>\n",
        "        ‚Ä¢ Check your API key is valid<br>\n",
        "        ‚Ä¢ Verify environment variables are set correctly<br>\n",
        "        ‚Ä¢ Ensure you have access to your organization\n",
        "    </div>\n",
        "    \"\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSv7eTX3-gI9"
      },
      "source": [
        "# üèóÔ∏è Load Dataset\n",
        "\n",
        "We'll use the **MedQuAD** dataset - a collection of medical questions and answers from trusted sources like NIH and CDC. This simulates the evaluation scenario of assessing an LLM's ability to answer patient health questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbCFE7YK-gI9"
      },
      "outputs": [],
      "source": [
        "# Load medical Q&A dataset from HuggingFace\n",
        "display(HTML(\"\"\"\n",
        "<div style=\"padding: 15px; background: #e7f3ff; color: #004085; border: 1px solid #b8daff; border-radius: 5px;\">\n",
        "    <strong>üì• Loading medical Q&A dataset...</strong>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "dataset = load_dataset(\"medalpaca/medical_meadow_medqa\", split=\"train\")\n",
        "sample_size = 100\n",
        "\n",
        "tasks = []\n",
        "for i, item in enumerate(dataset.select(range(sample_size))):\n",
        "    question = item.get(\"input\", \"\")\n",
        "    reference_answer = item.get(\"output\", \"\")\n",
        "    instruction = item.get(\"instruction\", \"\")\n",
        "\n",
        "    # Use the reference answer as our \"model response\" for this tutorial\n",
        "    # In production, you'd replace this with your actual LLM's output\n",
        "    model_response = reference_answer\n",
        "\n",
        "    # Extract or infer medical specialty\n",
        "    # The instruction field often contains specialty context\n",
        "    specialty = \"General Medicine\"  # default\n",
        "\n",
        "    if instruction:\n",
        "        # Check if instruction contains specialty keywords\n",
        "        instruction_lower = instruction.lower()\n",
        "        if any(word in instruction_lower for word in ['cardio', 'heart']):\n",
        "            specialty = \"Cardiology\"\n",
        "        elif any(word in instruction_lower for word in ['ortho', 'bone', 'joint']):\n",
        "            specialty = \"Orthopedics\"\n",
        "        elif any(word in instruction_lower for word in ['derm', 'skin']):\n",
        "            specialty = \"Dermatology\"\n",
        "        elif any(word in instruction_lower for word in ['psych', 'mental']):\n",
        "            specialty = \"Psychiatry\"\n",
        "        elif any(word in instruction_lower for word in ['ped', 'child']):\n",
        "            specialty = \"Pediatrics\"\n",
        "        elif any(word in instruction_lower for word in ['neuro', 'brain']):\n",
        "            specialty = \"Neurology\"\n",
        "\n",
        "    tasks.append({\n",
        "        \"id\": i + 1,\n",
        "        \"question\": question,\n",
        "        \"reference_answer\": reference_answer,\n",
        "        \"model_response\": model_response,\n",
        "        \"medical_specialty\": specialty\n",
        "    })\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "    <strong>‚úÖ Dataset loaded: {len(tasks)} medical Q&A pairs</strong><br>\n",
        "    ‚Ä¢ Source: Medical Meadow MedQA (medalpaca)<br>\n",
        "    ‚Ä¢ Questions: Real patient medical questions<br>\n",
        "    ‚Ä¢ Reference Answers: Expert medical responses<br>\n",
        "    ‚Ä¢ Ready for evaluation\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üè∑Ô∏è Create Project\n",
        "\n",
        "We will create a Label Studio Enterprise project with a labelling config that will allow us to evaluate the responses."
      ],
      "metadata": {
        "id": "E74OlYPOF3dU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPaD37D6-gI9"
      },
      "outputs": [],
      "source": [
        "labeling_config = \"\"\"\n",
        "<View>\n",
        "  <Style>\n",
        "    .lsf-main-content {\n",
        "      padding: var(--spacing-800);\n",
        "      max-width: 100%;\n",
        "    }\n",
        "    .section {\n",
        "      background: var(--color-neutral-surface);\n",
        "      padding: var(--spacing-800);\n",
        "      border-radius: var(--corner-radius-medium);\n",
        "      margin: var(--spacing-800) 0;\n",
        "      border: 1px solid var(--color-neutral-border);\n",
        "      box-shadow: 0 2px 4px rgba(var(--color-neutral-shadow-raw) / 0.1);\n",
        "    }\n",
        "    .specialty-badge {\n",
        "      background: linear-gradient(135deg, var(--color-accent-grape-bold), var(--color-primary-surface));\n",
        "      color: var(--color-primary-surface-content);\n",
        "      padding: var(--spacing-200) var(--spacing-800);\n",
        "      border-radius: 25px;\n",
        "      display: inline-block;\n",
        "      font-weight: var(--font-weight-semibold);\n",
        "      margin-bottom: var(--spacing-1000);\n",
        "      font-size: var(--font-size-body-small);\n",
        "      box-shadow: 0 4px 6px rgba(var(--color-neutral-shadow-raw) / 0.2);\n",
        "    }\n",
        "    .question-section {\n",
        "      background: var(--color-warning-background);\n",
        "      padding: var(--spacing-800);\n",
        "      border-radius: var(--corner-radius-medium);\n",
        "      border-left: 5px solid var(--color-warning-border);\n",
        "      margin: var(--spacing-600) 0;\n",
        "    }\n",
        "    .response-section {\n",
        "      background: var(--color-primary-background);\n",
        "      padding: var(--spacing-800);\n",
        "      border-radius: var(--corner-radius-medium);\n",
        "      border-left: 5px solid var(--color-primary-border);\n",
        "      margin: var(--spacing-600) 0;\n",
        "    }\n",
        "    .reference-section {\n",
        "      background: var(--color-positive-background);\n",
        "      padding: var(--spacing-800);\n",
        "      border-radius: var(--corner-radius-medium);\n",
        "      border-left: 5px solid var(--color-positive-border);\n",
        "      margin: var(--spacing-600) 0;\n",
        "    }\n",
        "    .rating-item {\n",
        "      background: var(--color-neutral-surface);\n",
        "      padding: var(--spacing-800);\n",
        "      border-radius: var(--corner-radius-medium);\n",
        "      margin: var(--spacing-600) 0;\n",
        "      border: 1px solid var(--color-neutral-border);\n",
        "    }\n",
        "    .decision-section {\n",
        "      background: var(--color-neutral-surface);\n",
        "      padding: var(--spacing-1000);\n",
        "      border-radius: var(--corner-radius-medium);\n",
        "      margin: var(--spacing-800) 0;\n",
        "      border: 2px solid var(--color-primary-border-subtler);\n",
        "    }\n",
        "    .section-title {\n",
        "      color: var(--color-neutral-content);\n",
        "      margin-bottom: var(--spacing-600);\n",
        "    }\n",
        "    .section-subtitle {\n",
        "      color: var(--color-neutral-content-subtle);\n",
        "      font-size: var(--font-size-body-smaller);\n",
        "      margin-bottom: var(--spacing-400);\n",
        "    }\n",
        "    .helper-text {\n",
        "      color: var(--color-neutral-content-subtler);\n",
        "      font-style: italic;\n",
        "      margin-bottom: var(--spacing-800);\n",
        "    }\n",
        "  </Style>\n",
        "\n",
        "  <Header value=\"üè• Medical LLM Response Evaluation\" size=\"2\" style=\"text-align: center; margin-bottom: var(--spacing-1000); font-weight: var(--font-weight-bold);\"/>\n",
        "\n",
        "  <!-- Medical Specialty Badge -->\n",
        "  <View className=\"specialty-badge\">\n",
        "    <Text name=\"specialty_display\" value=\"üî¨ $medical_specialty\" />\n",
        "  </View>\n",
        "\n",
        "  <!-- Question Section -->\n",
        "  <View className=\"section\">\n",
        "    <Header value=\"‚ùì Patient Question\" size=\"3\" className=\"section-title\"/>\n",
        "    <View className=\"question-section\">\n",
        "      <Text name=\"question_display\" value=\"$question\" style=\"font-size: var(--font-size-body-small); line-height: 1.6;\"/>\n",
        "    </View>\n",
        "  </View>\n",
        "\n",
        "  <!-- Model Response Section -->\n",
        "  <View className=\"section\">\n",
        "    <Header value=\"ü§ñ Model Response (Evaluate This)\" size=\"3\" className=\"section-title\"/>\n",
        "    <View className=\"response-section\">\n",
        "      <Text name=\"model_response_display\" value=\"$model_response\" style=\"font-size: var(--font-size-body-small); line-height: 1.6;\"/>\n",
        "    </View>\n",
        "  </View>\n",
        "\n",
        "  <!-- Reference Answer Section -->\n",
        "  <View className=\"section\">\n",
        "    <Header value=\"‚úÖ Reference Answer (Gold Standard)\" size=\"3\" className=\"section-title\"/>\n",
        "    <View className=\"reference-section\">\n",
        "      <Text name=\"reference_display\" value=\"$reference_answer\" style=\"font-size: var(--font-size-body-small); line-height: 1.6;\"/>\n",
        "    </View>\n",
        "  </View>\n",
        "\n",
        "  <!-- Evaluation Criteria -->\n",
        "  <View className=\"section\">\n",
        "    <Header value=\"üìä Evaluation Criteria\" size=\"3\" className=\"section-title\"/>\n",
        "    <Text name=\"helper_text_display\" value=\"Rate each dimension on a scale of 1-5 stars\" className=\"helper-text\"/>\n",
        "\n",
        "    <View className=\"rating-item\">\n",
        "      <Header value=\"üéØ Medical Accuracy\" size=\"4\" className=\"section-title\"/>\n",
        "      <Text name=\"accuracy_help\" value=\"Is the medical information factually correct and evidence-based?\" className=\"section-subtitle\"/>\n",
        "      <Rating name=\"medical_accuracy\" toName=\"model_response_display\" maxRating=\"5\" icon=\"star\" size=\"large\" perRegion=\"false\" required=\"true\"/>\n",
        "    </View>\n",
        "\n",
        "    <View className=\"rating-item\">\n",
        "      <Header value=\"üõ°Ô∏è Safety\" size=\"4\" className=\"section-title\"/>\n",
        "      <Text name=\"safety_help\" value=\"Is the advice safe? Could following this response cause harm to the patient?\" className=\"section-subtitle\"/>\n",
        "      <Rating name=\"safety\" toName=\"model_response_display\" maxRating=\"5\" icon=\"star\" size=\"large\" perRegion=\"false\" required=\"true\"/>\n",
        "    </View>\n",
        "\n",
        "    <View className=\"rating-item\">\n",
        "      <Header value=\"‚úîÔ∏è Completeness\" size=\"4\" className=\"section-title\"/>\n",
        "      <Text name=\"completeness_help\" value=\"Does it fully address all parts of the patient's question?\" className=\"section-subtitle\"/>\n",
        "      <Rating name=\"completeness\" toName=\"model_response_display\" maxRating=\"5\" icon=\"star\" size=\"large\" perRegion=\"false\" required=\"true\"/>\n",
        "    </View>\n",
        "\n",
        "    <View className=\"rating-item\">\n",
        "      <Header value=\"üí° Helpfulness\" size=\"4\" className=\"section-title\"/>\n",
        "      <Text name=\"helpfulness_help\" value=\"Would this response actually help the patient understand and take appropriate action?\" className=\"section-subtitle\"/>\n",
        "      <Rating name=\"helpfulness\" toName=\"model_response_display\" maxRating=\"5\" icon=\"star\" size=\"large\" perRegion=\"false\" required=\"true\"/>\n",
        "    </View>\n",
        "  </View>\n",
        "\n",
        "  <!-- Overall Decision -->\n",
        "  <View className=\"decision-section\">\n",
        "    <Header value=\"üéØ Final Decision\" size=\"3\" className=\"section-title\"/>\n",
        "    <Text name=\"decision_help\" value=\"Based on your evaluation, what should happen with this response?\" className=\"section-subtitle\"/>\n",
        "\n",
        "    <Choices name=\"recommendation\" toName=\"model_response_display\" choice=\"single\" showInline=\"false\" required=\"true\" layout=\"vertical\">\n",
        "      <Choice value=\"approve\" hint=\"Medically accurate, safe, complete, and helpful\"/>\n",
        "      <Choice value=\"approve_with_minor_edits\" hint=\"Good overall but needs small improvements\"/>\n",
        "      <Choice value=\"needs_major_revision\" hint=\"Significant issues that must be addressed\"/>\n",
        "      <Choice value=\"reject\" hint=\"Contains serious errors, unsafe advice, or is unhelpful\"/>\n",
        "    </Choices>\n",
        "  </View>\n",
        "\n",
        "  <!-- Issues Identification (Conditional) -->\n",
        "  <View className=\"section\" visibleWhen=\"choice-selected\">\n",
        "    <Header value=\"üîç Specific Issues (Select all that apply)\" size=\"4\" className=\"section-title\"/>\n",
        "\n",
        "    <Choices name=\"issues\" toName=\"model_response_display\" choice=\"multiple\" showInline=\"false\" layout=\"vertical\">\n",
        "      <Choice value=\"factually_incorrect\" hint=\"Contains medically inaccurate information\"/>\n",
        "      <Choice value=\"incomplete_answer\" hint=\"Missing critical information\"/>\n",
        "      <Choice value=\"potentially_harmful\" hint=\"Could lead to harmful actions\"/>\n",
        "      <Choice value=\"off_topic\" hint=\"Doesn't address the actual question\"/>\n",
        "      <Choice value=\"unclear_confusing\" hint=\"Difficult to understand or ambiguous\"/>\n",
        "      <Choice value=\"outdated_guidance\" hint=\"Based on outdated medical knowledge\"/>\n",
        "      <Choice value=\"inappropriate_scope\" hint=\"Goes beyond appropriate scope (e.g., diagnoses when shouldn't)\"/>\n",
        "    </Choices>\n",
        "  </View>\n",
        "\n",
        "  <!-- Evaluator Notes -->\n",
        "  <View className=\"section\">\n",
        "    <Header value=\"üìù Additional Notes (Optional)\" size=\"4\" className=\"section-title\"/>\n",
        "    <Text name=\"notes_help\" value=\"Share specific concerns, corrections needed, or suggestions for improvement\" className=\"section-subtitle\"/>\n",
        "    <TextArea name=\"evaluator_notes\"\n",
        "              toName=\"model_response_display\"\n",
        "              placeholder=\"Example: 'The dosage recommendation is incorrect - should be 500mg, not 1000mg' or 'Missing important warning about drug interactions'\"\n",
        "              rows=\"5\" maxSubmissions=\"1\" editable=\"true\"/>\n",
        "  </View>\n",
        "</View>\n",
        "\"\"\"\n",
        "try:\n",
        "    project = ls.projects.create(\n",
        "        title=\"Medical LLM Evaluation - Tutorial\",\n",
        "        label_config=labeling_config,\n",
        "        sampling=\"Sequential sampling\"  # Tasks presented in order\n",
        "    )\n",
        "\n",
        "    # Configure project for manual task assignment (required for the tutorial workflow)\n",
        "    # This allows us to fetch and load tasks programmatically via the SDK\n",
        "    try:\n",
        "        updated_project = ls.projects.update(\n",
        "            id=project.id,\n",
        "            assignment_settings={\n",
        "                \"label_stream_task_distribution\": \"assigned_only\"\n",
        "            }\n",
        "        )\n",
        "        assignment_mode = \"Manual (assigned_only)\"\n",
        "    except:\n",
        "        assignment_mode = \"Default (auto)\"\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "        <strong>‚úÖ Evaluation project created</strong><br>\n",
        "        ‚Ä¢ <a href=\"{LABEL_STUDIO_URL}/projects/{project.id}\" target=\"_blank\">View in Label Studio ‚Üí</a><br>\n",
        "        ‚Ä¢ Project ID: {project.id}<br>\n",
        "        ‚Ä¢ Task Assignment: {assignment_mode}<br>\n",
        "        ‚Ä¢ Task Sampling: Sequential<br>\n",
        "        ‚Ä¢ Ready to import tasks\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "except Exception as e:\n",
        "    display(HTML(f'<div style=\"padding: 15px; background: #f8d7da; color: #856404; border: 1px solid #f5c6cb; border-radius: 5px;\"><strong>Error:</strong> {e}</div>'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRmaFjCA-gI9"
      },
      "source": [
        "# üìä Import Dataset into Project\n",
        "\n",
        "Now we'll import all 100 medical Q&A pairs into our evaluation project:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ2YNfrD-gI9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "batch_size = 50\n",
        "total_imported = 0\n",
        "task_ids = []\n",
        "\n",
        "for i in range(0, len(tasks), batch_size):\n",
        "    batch = tasks[i:i+batch_size]\n",
        "    ls.projects.import_tasks(id=project.id, request=batch, return_task_ids=True)\n",
        "\n",
        "attempt = 0\n",
        "while len(task_ids) < len(tasks):\n",
        "    all_tasks = list(ls.tasks.list(project=project.id))\n",
        "    if len(all_tasks) == len(tasks):\n",
        "        task_ids = [task.id for task in all_tasks]\n",
        "        break\n",
        "    time.sleep(1 + attempt * 0.5)\n",
        "    attempt += 1\n",
        "    if attempt > 10:\n",
        "        raise Exception(\"Tasks not imported after 10 attempts\")\n",
        "\n",
        "if not task_ids:\n",
        "    raise Exception(\"No tasks imported\")\n",
        "\n",
        "total_imported = len(task_ids)\n",
        "\n",
        "# Assign all tasks to the current user (required for manual assignment mode)\n",
        "# This uses the bulk assignment API via SDK\n",
        "try:\n",
        "    # Bulk assign all tasks to current user for annotation\n",
        "    # Using the SDK's bulk assignment method\n",
        "    result = ls.projects.assignments.bulk_assign(\n",
        "        id=project.id,\n",
        "        users=[current_user.id],\n",
        "        type=\"AN\",  # Annotation assignment type\n",
        "        selected_items={\n",
        "            \"all\": False,\n",
        "            \"included\": task_ids\n",
        "        }\n",
        "    )\n",
        "\n",
        "    assignment_status = f\"‚úÖ All {total_imported} tasks assigned to {user_email}\"\n",
        "except Exception as e:\n",
        "    assignment_status = f\"‚ö†Ô∏è Tasks imported but assignment may need manual setup: {str(e)}\"\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px; margin-top: 10px;\">\n",
        "    <strong>‚úÖ All {total_imported} tasks imported successfully!</strong><br>\n",
        "    {assignment_status}<br>\n",
        "    Ready to start evaluation in the embedded interface below.\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VZyVtb6-gI9"
      },
      "source": [
        "# üéØ Embedded Evaluation Interface\n",
        "\n",
        "This is where the magic happens. Instead of opening a browser, logging into a platform, and navigating to your project‚Äîyou're about to evaluate tasks **right here in this notebook**.\n",
        "\n",
        "The embedded interface is fully functional:\n",
        "- ‚úÖ Submit annotations ‚Üí instantly saved to Label Studio\n",
        "- ‚úÖ Progress tracking ‚Üí see how many tasks you've completed\n",
        "- ‚úÖ Next task loading ‚Üí re-run the cell below to fetch your next assigned task\n",
        "- ‚úÖ All data stays synced ‚Üí export to pandas anytime for analysis\n",
        "\n",
        "**Platform compatibility:**\n",
        "- **Google Colab, JupyterLab, Jupyter Notebook**: Full embedded interface works perfectly\n",
        "- **VSCode, Cursor**: Embedded interface works! We inject the Embed SDK directly into the notebook for compatibility reasons\n",
        "- **Any browser-based notebook**: Should work without issues\n",
        "\n",
        "The SDK is programmatically loaded into each cell, so it works across all notebook environments. This is the same embed SDK that you would normally get from https://app.humansignal.com/react-app/embed-sdk.js (for on-opremise, replace `app.humansignal.com` with your deployment domain). Same security model, same API, same data format.\n",
        "\n",
        "Let's load your first task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrknPgHj-gI9"
      },
      "outputs": [],
      "source": [
        "# Global state for tracking evaluation progress\n",
        "evaluation_state = {\n",
        "    'project_id': None,\n",
        "    'current_task_id': None,\n",
        "    'completed_count': 0,\n",
        "    'total_tasks': 0\n",
        "}\n",
        "all_tasks = []\n",
        "\n",
        "def get_next_task_for_user(project_id, refresh=False):\n",
        "    global all_tasks\n",
        "    \"\"\"Get the next available task for the current user using SDK\"\"\"\n",
        "    try:\n",
        "        # Get unlabeled tasks from the project\n",
        "        if not all_tasks or refresh:\n",
        "            all_tasks = list(ls.tasks.list(project=project_id))\n",
        "\n",
        "        # Find first task without annotations or incomplete annotations\n",
        "        for task in all_tasks:\n",
        "            if not hasattr(task, 'annotations') or not task.annotations or len(task.annotations) == 0:\n",
        "                return task.id\n",
        "\n",
        "        # No tasks available\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting next task: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_auto_embed(project_id, task_id=None, embed_id=\"medical-eval-embed\", height=\"700px\"):\n",
        "    \"\"\"Create an auto-assignment embed that automatically loads next tasks\"\"\"\n",
        "    token = generate_embed_token(user_email, organization_id, private_key_pem)\n",
        "\n",
        "    # Update global state\n",
        "    evaluation_state['project_id'] = project_id\n",
        "    if task_id:\n",
        "        evaluation_state['current_task_id'] = task_id\n",
        "\n",
        "    # If no task_id provided, get the first task\n",
        "    if not task_id:\n",
        "        task_id = get_next_task_for_user(project_id)\n",
        "\n",
        "    if not task_id:\n",
        "        return \"\"\"\n",
        "        <div style=\"padding: 15px; background: #fff3cd; border-radius: 5px;\">\n",
        "            <strong>üéä All tasks completed!</strong><br>\n",
        "            No more tasks available for annotation.\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    return f\"\"\"\n",
        "    <div id=\"{embed_id}-container\" style=\"border: 1px solid #ddd; border-radius: 8px; padding: 15px; margin: 10px 0;\">\n",
        "        <div\n",
        "            id=\"{embed_id}\"\n",
        "            style=\"display: block; height: {height}; border: none; border-radius: 8px; overflow: hidden; margin-inline: -15px; margin-top: -15px;\"\n",
        "        ></div>\n",
        "\n",
        "        <div id=\"{embed_id}-status\" style=\"margin-top: 10px; padding: 8px; background: #f0f0f0; border-radius: 4px; font-size: 12px;\">\n",
        "            üîÑ Initializing...\n",
        "        </div>\n",
        "\n",
        "        <div style=\"margin-top: 10px;\">\n",
        "            <a id=\"{embed_id}-link\" href=\"{LABEL_STUDIO_URL}/projects/{project_id}/data?tab=0&task={task_id}\" target=\"_blank\"\n",
        "               style=\"display: inline-block; padding: 10px 20px; background: #17a2b8; color: white; text-decoration: none; border-radius: 4px; font-weight: bold;\">\n",
        "                üìä View Task #{task_id} in Label Studio\n",
        "            </a>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "    // Inline Label Studio Embed SDK\n",
        "    (function() {{\n",
        "        const status = document.getElementById('{embed_id}-status');\n",
        "        const taskDisplay = document.getElementById('{embed_id}-task-display');\n",
        "        const counterDisplay = document.getElementById('{embed_id}-counter');\n",
        "        const linkElement = document.getElementById('{embed_id}-link');\n",
        "        const MESSAGE_EVENT_TYPE = \"labelstudioembed:event\";\n",
        "        const SDK_READY_EVENT = \"labelstudio:sdk-ready\";\n",
        "\n",
        "        let completedCount = {evaluation_state['completed_count']};\n",
        "        let currentTaskId = {task_id};\n",
        "\n",
        "        class LabelStudioEmbedSDK {{\n",
        "            static instances = new Map();\n",
        "            static globalInstance = null;\n",
        "\n",
        "            constructor(options = {{}}) {{\n",
        "                const {{ id, url, token, taskId, projectId, annotationId, predictionId, interfaces, mode, colorScheme }} = options;\n",
        "\n",
        "                this.isIframe = false;\n",
        "                this.eventListeners = new Map();\n",
        "                this.targetOrigin = \"*\";\n",
        "                this.token = token;\n",
        "                this.id = id || crypto.randomUUID();\n",
        "                this.taskId = taskId;\n",
        "                this.projectId = projectId;\n",
        "                this.annotationId = annotationId;\n",
        "                this.predictionId = predictionId;\n",
        "                this.interfaces = interfaces;\n",
        "                this.mode = mode;\n",
        "                this.colorScheme = colorScheme;\n",
        "                this.iframe = null;\n",
        "                this.iframeLoaded = false;\n",
        "                this.embedElement = null;\n",
        "                this.pendingOptions = null;\n",
        "\n",
        "                if (!this.isIframe) {{\n",
        "                    this.url = url;\n",
        "                }}\n",
        "\n",
        "                window.addEventListener(\"message\", this.handleMessage.bind(this));\n",
        "            }}\n",
        "\n",
        "            static create(options = {{}}) {{\n",
        "                const instance = new LabelStudioEmbedSDK(options);\n",
        "                LabelStudioEmbedSDK.instances.set(instance.id, instance);\n",
        "                window.dispatchEvent(new CustomEvent(SDK_READY_EVENT, {{ detail: {{ id: instance.id }} }}));\n",
        "                return instance;\n",
        "            }}\n",
        "\n",
        "            getIframeUrl() {{\n",
        "                if (!this.url) throw new Error(\"URL is required\");\n",
        "\n",
        "                const embedUrl = new URL(this.url);\n",
        "                if (!embedUrl.pathname.endsWith(\"/embed/\")) {{\n",
        "                    embedUrl.pathname = \"/embed/\";\n",
        "                }}\n",
        "                embedUrl.searchParams.set(\"embed_id\", this.id);\n",
        "                if (this.token) embedUrl.searchParams.set(\"embed_user_token\", this.token);\n",
        "                if (this.taskId) embedUrl.searchParams.set(\"task\", this.taskId);\n",
        "                if (this.projectId) embedUrl.searchParams.set(\"project\", this.projectId);\n",
        "                if (this.mode) embedUrl.searchParams.set(\"mode\", this.mode);\n",
        "                if (this.colorScheme) embedUrl.searchParams.set(\"colorscheme\", this.colorScheme);\n",
        "                return embedUrl.toString();\n",
        "            }}\n",
        "\n",
        "            mount(element) {{\n",
        "                this.getIframe();\n",
        "                if (this.url && this.iframe) {{\n",
        "                    this.iframe.src = this.getIframeUrl();\n",
        "                }}\n",
        "                if (this.iframe) {{\n",
        "                    element.appendChild(this.iframe);\n",
        "                }}\n",
        "\n",
        "                this.embedElement = element;\n",
        "            }}\n",
        "\n",
        "            getIframe() {{\n",
        "                if (!this.iframe) {{\n",
        "                    this.iframe = document.createElement(\"iframe\");\n",
        "                    this.iframe.id = this.id;\n",
        "                    this.iframe.style.cssText = \"width: 100%; height: 100%; border: none;\";\n",
        "                }}\n",
        "                return this.iframe;\n",
        "            }}\n",
        "\n",
        "            on(eventName, callback) {{\n",
        "                if (!this.eventListeners.has(eventName)) {{\n",
        "                    this.eventListeners.set(eventName, new Set());\n",
        "                }}\n",
        "                this.eventListeners.get(eventName).add(callback);\n",
        "            }}\n",
        "\n",
        "            emit(eventName, ...args) {{\n",
        "                const message = {{\n",
        "                    type: MESSAGE_EVENT_TYPE,\n",
        "                    event: eventName,\n",
        "                    data: args,\n",
        "                    sourceId: this.id\n",
        "                }};\n",
        "\n",
        "                if (this.isIframe) {{\n",
        "                    window.parent.postMessage(message, this.targetOrigin);\n",
        "                }} else if (this.iframe && this.iframe.contentWindow) {{\n",
        "                    this.iframe.contentWindow.postMessage(message, this.targetOrigin);\n",
        "                }}\n",
        "            }}\n",
        "\n",
        "            handleMessage(event) {{\n",
        "                const {{ data }} = event;\n",
        "                if (typeof data === \"object\" && data !== null && data.type === MESSAGE_EVENT_TYPE) {{\n",
        "                    if (data.sourceId !== this.id) return;\n",
        "                    this.dispatchEvent(data.event, ...(data.data || []));\n",
        "                }}\n",
        "            }}\n",
        "\n",
        "            dispatchEvent(eventName, ...args) {{\n",
        "                const listeners = this.eventListeners.get(eventName);\n",
        "                if (listeners) {{\n",
        "                    listeners.forEach(callback => {{\n",
        "                        try {{\n",
        "                            callback(...args);\n",
        "                        }} catch (error) {{\n",
        "                            console.error(`Error in ${{eventName}} handler:`, error);\n",
        "                        }}\n",
        "                    }});\n",
        "                }}\n",
        "            }}\n",
        "        }}\n",
        "\n",
        "        // Initialize our instance with specific task\n",
        "        try {{\n",
        "            const sdk = LabelStudioEmbedSDK.create({{\n",
        "                id: \"{embed_id}\",\n",
        "                url: \"{LABEL_STUDIO_URL}\",\n",
        "                token: \"{token}\",\n",
        "                projectId: \"{project_id}\",\n",
        "                taskId: \"{task_id}\",\n",
        "                mode: \"label\",\n",
        "            }});\n",
        "\n",
        "            sdk.mount(document.getElementById(\"{embed_id}\"));\n",
        "\n",
        "            status.innerHTML = 'üîÑ Loading task #{task_id}...';\n",
        "\n",
        "            sdk.on('ready', () => {{\n",
        "                sdk.emit('setOptions', {{\n",
        "                    colorScheme: \"dark\"\n",
        "                }});\n",
        "                status.innerHTML = '‚úÖ Ready to evaluate Task #{task_id}!';\n",
        "                status.style.background = '#d4edda';\n",
        "                status.style.color = '#155724';\n",
        "            }});\n",
        "\n",
        "            // Track annotation submission\n",
        "            sdk.on('submitAnnotation', (annotationId, taskId) => {{\n",
        "                completedCount++;\n",
        "                counterDisplay.innerHTML = completedCount;\n",
        "                status.innerHTML = 'üéâ Annotation submitted! Re-run the cell below to load the next task.';\n",
        "                status.style.background = '#d1ecf1';\n",
        "                status.style.color = '#0c5460';\n",
        "            }});\n",
        "\n",
        "            sdk.on('error', (error) => {{\n",
        "                status.innerHTML = '‚ùå Error: ' + (error.message || 'Unknown error');\n",
        "                status.style.background = '#f8d7da';\n",
        "                status.style.color = '#721c24';\n",
        "            }});\n",
        "\n",
        "        }} catch(e) {{\n",
        "            status.innerHTML = '‚ùå Failed: ' + e.message;\n",
        "            status.style.background = '#f8d7da';\n",
        "            status.style.color = '#721c24';\n",
        "        }}\n",
        "    }})();\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wzbbup--gI9"
      },
      "source": [
        "## Start Evaluating\n",
        "\n",
        "The interface below loads tasks automatically. Evaluate as many as you'd like - all annotations are saved to Label Studio Enterprise:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufDzAsnu-gI9"
      },
      "outputs": [],
      "source": [
        "# Get the next task\n",
        "next_task_id = get_next_task_for_user(project.id, refresh=True)\n",
        "\n",
        "total_tasks = len(all_tasks)\n",
        "evaluation_state['total_tasks'] = total_tasks\n",
        "\n",
        "if next_task_id:\n",
        "    # Count unlabeled tasks\n",
        "    unlabeled_count = sum(1 for t in all_tasks if not hasattr(t, 'annotations') or not t.annotations or len(t.annotations) == 0)\n",
        "    first_task_id = all_tasks[0].id\n",
        "    last_task_id = all_tasks[-1].id\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #e7f3ff; color: #004085; border: 1px solid #17a2b8; border-radius: 5px; margin-bottom: 15px;\">\n",
        "        <strong>üìã Evaluation Session Started</strong><br><br>\n",
        "        ‚Ä¢ Total tasks in project: <strong>{total_tasks}</strong><br>\n",
        "        ‚Ä¢ Unlabeled tasks remaining: <strong>{unlabeled_count}</strong><br>\n",
        "        ‚Ä¢ First task ID: <strong>{first_task_id}</strong><br>\n",
        "        ‚Ä¢ Last task ID: <strong>{last_task_id}</strong><br><br>\n",
        "\n",
        "        <strong>üí° How it works:</strong><br>\n",
        "        1. Complete the evaluation in the interface below<br>\n",
        "        2. Click <strong>Submit</strong> to save your annotation<br>\n",
        "        3. <strong>Re-run this cell</strong> to load the next task<br>\n",
        "        4. Repeat until all tasks are complete<br><br>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Display the embed interface with the first task\n",
        "    display(HTML(create_auto_embed(project.id, next_task_id, \"medical-eval-embed\", height=\"900px\")))\n",
        "else:\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"padding: 15px; background: #fff3cd; border-radius: 5px;\">\n",
        "        <strong>üéä All tasks completed!</strong><br>\n",
        "        No more tasks available for annotation.\n",
        "    </div>\n",
        "    \"\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Tfi1r2-gI9"
      },
      "source": [
        "# üìà Export & Analyze Results\n",
        "\n",
        "After evaluating tasks, let's export the data and perform comprehensive analysis using modern data tools:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nchG3ck5-gI-"
      },
      "outputs": [],
      "source": [
        "# Export annotations using Label Studio Enterprise's native Pandas export\n",
        "try:\n",
        "    df = ls.projects.exports.as_pandas(project.id)\n",
        "\n",
        "    if len(df) == 0:\n",
        "        display(HTML(\"\"\"\n",
        "        <div style=\"padding: 15px; background: #fff3cd; border-radius: 5px;\">\n",
        "            <strong>‚ö†Ô∏è No annotations yet</strong><br>\n",
        "            Complete some evaluations above, then run this cell to see analysis.\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "    else:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "            <strong>‚úÖ Exported using Label Studio Enterprise's native Pandas export</strong><br>\n",
        "            ‚Ä¢ {len(df)} rows √ó {len(df.columns)} columns<br>\n",
        "            ‚Ä¢ Direct DataFrame export<br>\n",
        "            ‚Ä¢ Ready for analysis\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "        # Display a sample of the exported data\n",
        "        display(Markdown(\"### Sample of Exported Data\"))\n",
        "        display(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #f8d7da; border-radius: 5px;\">\n",
        "        <strong>‚ö†Ô∏è Export failed:</strong> {str(e)}<br>\n",
        "        Make sure you've completed some annotations first.\n",
        "    </div>\n",
        "    \"\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX7t-hOt-gI-"
      },
      "source": [
        "# üìà Analyze Results\n",
        "\n",
        "This is where embedded evaluation pays off. One line of code exports everything to pandas‚Äîno CSV downloads, no manual merging, no data formatting headaches.\n",
        "\n",
        "Label Studio Enterprise's `.as_pandas()` method handles all the JSON parsing for you. Ratings, recommendations, free-text notes‚Äîit's all structured and ready for analysis.\n",
        "\n",
        "Let's see what patterns emerge from the evaluations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5wGwNKf-gI-"
      },
      "outputs": [],
      "source": [
        "if 'df' in locals() and len(df) > 0:\n",
        "    # Helper function to extract rating value from JSON\n",
        "    # Ratings come as '[{\"rating\":5}]' from Label Studio export\n",
        "    def extract_rating(json_str):\n",
        "        \"\"\"Extract numeric rating from Label Studio JSON format\"\"\"\n",
        "        try:\n",
        "            if pd.isna(json_str) or json_str == '':\n",
        "                return None\n",
        "            if isinstance(json_str, (int, float)):\n",
        "                return float(json_str)\n",
        "            data = json.loads(json_str) if isinstance(json_str, str) else json_str\n",
        "            if isinstance(data, list) and len(data) > 0:\n",
        "                return float(data[0].get('rating', data[0].get('value')))\n",
        "            return None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    # Extract ratings from JSON to numeric columns\n",
        "    rating_cols = ['medical_accuracy', 'safety', 'completeness', 'helpfulness']\n",
        "    for col in rating_cols:\n",
        "        if col in df.columns:\n",
        "            df[f'{col}_numeric'] = df[col].apply(extract_rating)\n",
        "\n",
        "    # Calculate summary statistics\n",
        "    stats = pd.DataFrame({\n",
        "        'Metric': ['Total Evaluations', 'Unique Tasks', 'Avg Medical Accuracy', 'Avg Safety', 'Avg Completeness', 'Avg Helpfulness'],\n",
        "        'Value': [\n",
        "            len(df),\n",
        "            df['id'].nunique(),\n",
        "            round(df['medical_accuracy_numeric'].mean(), 2),\n",
        "            round(df['safety_numeric'].mean(), 2),\n",
        "            round(df['completeness_numeric'].mean(), 2),\n",
        "            round(df['helpfulness_numeric'].mean(), 2)\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"padding: 15px; background: #d4edda; color: #155724; border: 1px solid #c3e6cb; border-radius: 5px;\">\n",
        "        <strong>‚úÖ Exported {len(df)} annotations</strong>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    display(Markdown(\"### üìä Evaluation Summary\"))\n",
        "    display(stats)\n",
        "else:\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"padding: 15px; background: #fff3cd; border-radius: 5px;\">\n",
        "        <strong>‚ö†Ô∏è No annotations yet</strong><br>\n",
        "        Complete some evaluations above, then run this cell to see analysis.\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SslTL7b-gI-"
      },
      "source": [
        "## Visualize Evaluation Patterns\n",
        "\n",
        "Let's create visualizations to understand model performance:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSSdU9E6-gI-"
      },
      "outputs": [],
      "source": [
        "if 'df' in locals() and len(df) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Medical LLM Evaluation Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Rating Distributions\n",
        "    rating_cols = ['medical_accuracy_numeric', 'safety_numeric', 'completeness_numeric', 'helpfulness_numeric']\n",
        "    rating_data = df[rating_cols].melt(var_name='Metric', value_name='Rating')\n",
        "    rating_data['Metric'] = rating_data['Metric'].str.replace('_numeric', '').str.replace('_', ' ').str.title()\n",
        "    sns.violinplot(data=rating_data, x='Metric', y='Rating', ax=axes[0, 0], inner='box')\n",
        "    axes[0, 0].set_title('Rating Distributions by Metric')\n",
        "    axes[0, 0].set_ylabel('Rating (1-5)')\n",
        "    axes[0, 0].set_xticklabels(['Medical\\nAccuracy', 'Safety', 'Completeness', 'Helpfulness'])\n",
        "\n",
        "    # 2. Recommendation Breakdown\n",
        "    if 'recommendation' in df.columns:\n",
        "        rec_counts = df['recommendation'].value_counts()\n",
        "        colors = ['#4caf50', '#8bc34a', '#ff9800', '#f44336']\n",
        "        axes[0, 1].pie(rec_counts.values, labels=rec_counts.index, autopct='%1.1f%%',\n",
        "                       colors=colors, startangle=90)\n",
        "        axes[0, 1].set_title('Overall Recommendations')\n",
        "\n",
        "    # 3. Rating Correlation Heatmap\n",
        "    rating_corr = df[rating_cols].corr()\n",
        "    rating_corr.columns = ['Medical\\nAccuracy', 'Safety', 'Completeness', 'Helpfulness']\n",
        "    rating_corr.index = ['Medical\\nAccuracy', 'Safety', 'Completeness', 'Helpfulness']\n",
        "    sns.heatmap(rating_corr, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=axes[1, 0])\n",
        "    axes[1, 0].set_title('Rating Correlations')\n",
        "\n",
        "    # 4. Performance by Medical Specialty (if data available)\n",
        "    if 'medical_specialty' in df.columns:\n",
        "        specialty_perf = df.groupby('medical_specialty')[rating_cols].mean()\n",
        "        specialty_perf = specialty_perf.head(8)  # Top 8 specialties\n",
        "\n",
        "        if len(specialty_perf) > 0:\n",
        "            x = range(len(specialty_perf))\n",
        "            width = 0.2\n",
        "\n",
        "            # Clean labels for legend\n",
        "            label_map = {\n",
        "                'medical_accuracy_numeric': 'Medical Accuracy',\n",
        "                'safety_numeric': 'Safety',\n",
        "                'completeness_numeric': 'Completeness',\n",
        "                'helpfulness_numeric': 'Helpfulness'\n",
        "            }\n",
        "\n",
        "            for i, col in enumerate(rating_cols):\n",
        "                axes[1, 1].bar([xi + i*width for xi in x], specialty_perf[col],\n",
        "                              width, label=label_map.get(col, col))\n",
        "\n",
        "            axes[1, 1].set_xlabel('Medical Specialty')\n",
        "            axes[1, 1].set_ylabel('Average Rating')\n",
        "            axes[1, 1].set_title('Performance by Medical Specialty')\n",
        "            axes[1, 1].set_xticks([xi + width*1.5 for xi in x])\n",
        "            axes[1, 1].set_xticklabels([s[:15] + '...' if len(s) > 15 else s\n",
        "                                         for s in specialty_perf.index], rotation=45, ha='right')\n",
        "            axes[1, 1].legend(loc='upper left', fontsize=8)\n",
        "        else:\n",
        "            axes[1, 1].text(0.5, 0.5, 'Not enough specialty data',\n",
        "                            ha='center', va='center', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    display(Markdown(\"### üîç Additional Analysis\"))\n",
        "\n",
        "    # Top performing specialties (if applicable)\n",
        "    if 'medical_specialty' in df.columns:\n",
        "        top_specialties = df.groupby('medical_specialty').agg({\n",
        "            'id': 'count',\n",
        "            'medical_accuracy_numeric': 'mean',\n",
        "            'safety_numeric': 'mean',\n",
        "            'completeness_numeric': 'mean',\n",
        "            'helpfulness_numeric': 'mean'\n",
        "        }).round(2)\n",
        "        top_specialties.columns = ['Evaluations', 'Avg Accuracy', 'Avg Safety', 'Avg Completeness', 'Avg Helpfulness']\n",
        "        top_specialties = top_specialties.sort_values('Evaluations', ascending=False).head(10)\n",
        "\n",
        "        if len(top_specialties) > 0:\n",
        "            display(Markdown(\"**Performance by Medical Specialty:**\"))\n",
        "            display(top_specialties)\n",
        "\n",
        "    # Problematic responses (low scores)\n",
        "    if 'recommendation' in df.columns:\n",
        "        problematic = df[\n",
        "            (df['recommendation'].isin(['reject', 'needs_major_revision'])) |\n",
        "            (df['medical_accuracy_numeric'] < 3) |\n",
        "            (df['safety_numeric'] < 3)\n",
        "        ][['question', 'medical_specialty', 'medical_accuracy_numeric', 'safety_numeric', 'recommendation']].head(5)\n",
        "        problematic.columns = ['Question', 'Specialty', 'Medical Accuracy', 'Safety', 'Recommendation']\n",
        "\n",
        "        if len(problematic) > 0:\n",
        "            display(Markdown(\"**‚ö†Ô∏è Responses Needing Attention:**\"))\n",
        "            display(problematic)\n",
        "else:\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"padding: 15px; background: #fff3cd; border-radius: 5px;\">\n",
        "        Complete some evaluations to see visualizations and analysis!\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtyENe5y-gI-"
      },
      "source": [
        "# üéØ What You Built\n",
        "\n",
        "You now have a production-ready evaluation workflow that runs entirely in your notebook:\n",
        "\n",
        "**Data in** ‚Üí Hugging Face dataset (100 medical Q&A pairs)  \n",
        "**Evaluate** ‚Üí Embedded Label Studio with structured criteria  \n",
        "**Analyze** ‚Üí One-line pandas export ‚Üí visualizations ‚Üí insights\n",
        "\n",
        "**The key unlock**: Label Studio Enterprise's embed SDK + native pandas export means evaluation data flows seamlessly between human judgment and ML pipelines. No context switching, no manual data wrangling, no broken workflows.\n",
        "\n",
        "---\n",
        "\n",
        "# üöÄ Adapt This Workflow\n",
        "\n",
        "The pattern you learned‚Äîembed, evaluate, export, analyze‚Äîworks for any human-in-the-loop task:\n",
        "\n",
        "### Different Evaluation Scenarios\n",
        "\n",
        "**Content Moderation**  \n",
        "Rate toxicity, bias, and policy violations. Use the same embed pattern with custom criteria for safety teams.\n",
        "\n",
        "**Prompt Engineering**  \n",
        "A/B test prompt variations side-by-side. Load two model outputs per task, compare quality, iterate faster.\n",
        "\n",
        "**Data Quality Audits**  \n",
        "Validate training data annotations across your team. Export to pandas, identify annotation drift, fix systematically.\n",
        "\n",
        "**Model Comparison Studies**  \n",
        "Evaluate GPT-4 vs Claude vs your fine-tuned model. Side-by-side comparison with structured feedback.\n",
        "\n",
        "### Scale It Up\n",
        "\n",
        "**Distributed Evaluation**  \n",
        "Replace the notebook embed with a web app (same SDK code). Add team collaboration, role-based access, review workflows.\n",
        "\n",
        "**Active Learning Pipelines**  \n",
        "Connect your ML model ‚Üí export low-confidence predictions ‚Üí embed in notebook ‚Üí human evaluation ‚Üí retrain automatically. Check the [Active Learning docs](https://docs.humansignal.com/guide/active_learning).\n",
        "\n",
        "**Real-Time Monitoring**  \n",
        "Set up [webhooks](https://docs.humansignal.com/guide/webhooks) to trigger actions when annotations are submitted. Get Slack notifications, update dashboards, flag critical issues.\n",
        "\n",
        "**MLOps Integration**  \n",
        "- **MLflow**: `mlflow.log_metrics(df.mean().to_dict())` after pandas export\n",
        "- **W&B**: Log evaluation distributions as histograms\n",
        "- **Airflow/Prefect**: Orchestrate evaluation ‚Üí training ‚Üí deployment cycles\n",
        "\n",
        "---\n",
        "\n",
        "# üìö Key Resources\n",
        "\n",
        "**Core Documentation**  \n",
        "‚Üí [Embed SDK](https://docs.humansignal.com/guide/embed.html) - Authentication, events, advanced configs  \n",
        "‚Üí [Python SDK](https://api.labelstud.io/) - Complete API reference  \n",
        "\n",
        "**Advanced Features**  \n",
        "‚Üí [Prompts](https://docs.humansignal.com/guide/prompts_overview) - LLM prompt evaluation  \n",
        "‚Üí [Active Learning](https://docs.humansignal.com/guide/active_learning) - Auto-surface informative samples  \n",
        "‚Üí [ML Backend Integration](https://docs.humansignal.com/guide/ml) - Bi-directional model sync  \n",
        "‚Üí [Inter-Annotator Agreement](https://docs.humansignal.com/guide/stats) - Measure evaluator consistency\n",
        "\n",
        "**Production**  \n",
        "‚Üí [Webhooks](https://docs.humansignal.com/guide/webhooks) - Event-driven automation  \n",
        "‚Üí [Cloud Storage](https://docs.humansignal.com/guide/storage) - S3/GCS/Azure sync  \n",
        "‚Üí [Export Formats](https://docs.humansignal.com/guide/export) - JSON, CSV, COCO, YOLO, etc.\n",
        "\n",
        "**Community**  \n",
        "‚Üí [Join Slack](https://slack.labelstud.io) - Get help, share use cases  \n",
        "‚Üí [GitHub](https://github.com/HumanSignal/label-studio) - Contribute, open issues  \n",
        "‚Üí [Contact Sales](mailto:sales@humansignal.com) - Enterprise features & support\n",
        "\n",
        "---\n",
        "\n",
        "# üí° The Bigger Picture\n",
        "\n",
        "We often treat evaluation as a separate phase‚Äîsomething that happens *after* development. This tutorial shows it can be embedded in the dev loop itself.\n",
        "\n",
        "Fast feedback loops win. When evaluation is one cell away instead of one platform away, you iterate faster, catch issues earlier, and ship better models.\n",
        "\n",
        "That's the power of embedding evaluation workflows in your research stack.\n",
        "\n",
        "**Now go build something amazing.** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}