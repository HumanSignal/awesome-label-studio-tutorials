{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating models is only as good as the benchmark you test them against.  \n",
        "In this tutorial, you'll learn how to use **Label Studio** to create a high-quality benchmark dataset, label it with human expertise, and then evaluate multiple AI models against it â€” all using the **Label Studio SDK**.  \n",
        "\n",
        "By the end, you'll have a reproducible workflow to **measure and compare model performance** on your own data â€” moving beyond intuition and into measurable, data-driven insights.\n"
      ],
      "metadata": {
        "id": "v-NOwX1jcg-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Studio Requirements\n",
        "\n",
        "This tutorial showcases one or more features available only in Label Studio paid products. We recommend [creating a Starter Cloud trial](https://app.humansignal.com/user/cloud-trial?offer=d9a5&) to follow the tutorial."
      ],
      "metadata": {
        "id": "lDDShMwy6dg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§  What are benchmarks?\n",
        "\n",
        "A **benchmark** is a trusted, labeled dataset used as a ground truth reference to evaluate model performance.  \n",
        "Think of it as your *reality check* â€” it lets you see how well a model really understands your domain and tasks.  \n",
        "\n",
        "Unlike public leaderboards or off-the-shelf test sets, a **custom benchmark** reflects *your data, your domain, and your definition of success*.  \n",
        "For example, if you're detecting phishing emails, your benchmark should include real examples of legitimate and malicious messages relevant to your context.\n",
        "\n",
        "ðŸ‘‰ To learn more about the role of benchmarks in AI evaluation, see [**Why Benchmarks Matter for Evaluating LLMs**](https://labelstud.io/blog/why-benchmarks-matter-for-evaluating-llms/).\n"
      ],
      "metadata": {
        "id": "KHpOTyV1hWsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš–ï¸ Why are benchmarks important?\n",
        "\n",
        "Benchmarks are the backbone of **model evaluation and continuous improvement**. Without them, itâ€™s hard to know if a new model or prompt version actually performs better â€” or just seems to.  \n",
        "\n",
        "A good benchmark lets you:\n",
        "- ðŸ” Compare models from different providers on the *same data*  \n",
        "- ðŸ§© Identify strengths and weaknesses across labels or categories  \n",
        "- ðŸ“ˆ Track progress over time as your models evolve  \n",
        "- âœ… Build trust in your modelâ€™s predictions through measurable accuracy  \n",
        "\n",
        "In other words, benchmarks turn subjective â€œit looks betterâ€ claims into **objective evidence**.  \n",
        "For a deeper look at this idea, check out [**How to Build AI Benchmarks That Evolve with Your Models**](https://labelstud.io/blog/how-to-build-ai-benchmarks-that-evolve-with-your-models/).\n"
      ],
      "metadata": {
        "id": "ByRkXaL6hYSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ How can I use Label Studio to create my benchmark?\n",
        "\n",
        "Label Studio gives you everything you need to create, manage, and evolve your benchmark â€” all in one platform.  \n",
        "With it, you can:\n",
        "- ðŸ“¥ **Import and label your data** collaboratively or programmatically  \n",
        "- ðŸ§­ **Version and refine** your benchmark as your understanding improves  \n",
        "- ðŸ¤– **Run model evaluations** directly using the SDK and built-in prompt management tools  \n",
        "\n",
        "This makes your benchmarks *living assets* that adapt as your data and models grow.  \n",
        "For inspiration, see how others are building domain-specific benchmarks in [**How LegalBenchmarks.AI Built a Domain-Specific AI Benchmark**](https://labelstud.io/blog/how-legalbenchmarks-ai-built-a-domain-specific-ai-benchmark/).\n"
      ],
      "metadata": {
        "id": "kS3nL2dSh1Pm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŽ“ What is this tutorial going to teach me?\n",
        "\n",
        "In this tutorial, youâ€™ll learn how to:\n",
        "1. ðŸ—ï¸ Create a benchmark project in Label Studio using the SDK  \n",
        "2. ðŸ“Š Import and label your own dataset  \n",
        "3. ðŸ’¬ Define prompts and model versions to evaluate  \n",
        "4. ðŸ“‰ Run evaluations and visualize results  \n",
        "\n",
        "Weâ€™ll also walk through an example comparing several models on a phishing email classification task â€” similar to how we evaluated models in [**Evaluating the GPT-5 Series on Custom Benchmarks**](https://labelstud.io/blog/evaluating-the-gpt-5-series-on-custom-benchmarks/).  \n",
        "\n",
        "By the end, youâ€™ll have a repeatable workflow to **evaluate any model** on **any dataset** â€” grounded in your own benchmark."
      ],
      "metadata": {
        "id": "2w5l4Jjzh9tF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ Before You Start\n",
        "\n",
        "Before diving into the code, letâ€™s make sure you have everything set up to follow along.  \n",
        "\n",
        "Youâ€™ll only need a few things to get started ðŸ‘‡\n",
        "\n",
        "### ðŸ§° Prerequisites\n",
        "> **Note:** This tutorial is available for **Label Studio Enterprise** and **Starter Cloud** users, since it uses features like **Prompts** and **Agreement Metrics** that arenâ€™t available in the open-source version.\n",
        "\n",
        "If youâ€™re using the open-source version of Label Studio, you can still follow along conceptually.  \n",
        "ðŸ‘‰ Learn more or request access at [**humansignal.com**](https://humansignal.com/).\n",
        "\n",
        "Youâ€™ll need:\n",
        "- A **Label Studio account** on [app.humansignal.com](https://app.humansignal.com/)  \n",
        "  _(Starter Cloud or Enterprise edition required)_  \n",
        "- An **API key** from your user settings (youâ€™ll use it to connect via the SDK)  \n",
        "- Access to a **workspace** where you can create projects\n",
        "\n",
        "\n",
        "### ðŸ§© What youâ€™ll be using\n",
        "Weâ€™ll use the **Label Studio SDK** to:\n",
        "- Connect to your Label Studio instance  \n",
        "- Create a project and import data  \n",
        "- Define prompts and model versions  \n",
        "- Run model evaluations and visualize the results  \n",
        "\n",
        "Everything happens programmatically â€” no need to click around the UI (though you can open your Label Studio anytime to see whatâ€™s happening ðŸ‘€).\n",
        "\n",
        "Let's dive in ðŸš€\n"
      ],
      "metadata": {
        "id": "ogggN6ANiDGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš™ï¸ Install the SDK and connect to Label Studio\n",
        "\n",
        "Letâ€™s start by installing the SDK, configuring your connection details, and testing the connection.\n",
        "\n"
      ],
      "metadata": {
        "id": "vauOe_dOjiYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to install the Label Studio SDK\n",
        "!pip install label-studio-sdk>=2.0.11"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RmRELr5qkGoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure your connection details\n",
        "\n",
        "# URL of your Label Studio instance\n",
        "LABEL_STUDIO_URL = 'https://app.humansignal.com/'\n",
        "\n",
        "# Your API key (find it in Account & Settings > Personal Access Token)\n",
        "API_KEY = '<Token>'\n",
        "\n",
        "# ID of the workspace to create the project (make sure it's not the Personal Sandbox)\n",
        "# Find the Workspace ID in the URL when you click on it in the sidebar\n",
        "WORKSPACE_ID = 0"
      ],
      "metadata": {
        "id": "fAyS7DrKkIlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check you can connect to Label Studio\n",
        "from label_studio_sdk import LabelStudio\n",
        "\n",
        "ls = LabelStudio(base_url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
        "user = ls.users.whoami()\n",
        "print(f'Connected as {user.email}')"
      ],
      "metadata": {
        "id": "Jk-UY2eIv7fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Project and Import the Email Dataset\n",
        "\n",
        "1. We'll start by creating a **Label Studio project** with a labeling configuration that lets us classify each email as either **Phishing** or **Legitimate**.  \n",
        "   - If **Phishing** is selected, annotators can also choose one or more **phishing types** and **indicators** to describe the attack.\n",
        "\n",
        "2. Next, weâ€™ll **download a dataset of raw emails** that weâ€™ll use as the benchmark data.\n",
        "\n",
        "3. Finally, weâ€™ll **import the dataset as tasks into Label Studio**, so we can begin labeling and building our benchmark."
      ],
      "metadata": {
        "id": "bEoqDEhaw0kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_config = '''\n",
        "<View>\n",
        "  <View className=\"section\">\n",
        "    <Text name=\"body\" value=\"$raw_email\" />\n",
        "  </View>\n",
        "\n",
        "  <View className=\"section\">\n",
        "    <Header value=\"Overall classification\" size=\"3\" />\n",
        "    <Choices name=\"classification\" toName=\"body\" choice=\"single\" showInline=\"true\" required=\"true\">\n",
        "      <Choice value=\"Phishing\" />\n",
        "      <Choice value=\"Legitimate\" />\n",
        "    </Choices>\n",
        "  </View>\n",
        "\n",
        "  <View className=\"section\" visibleWhen=\"choice-selected\" whenTagName=\"classification\" whenChoiceValue=\"Phishing,Suspicious\">\n",
        "    <Header value=\"Phishing type\" size=\"3\" />\n",
        "    <Choices name=\"phishing_type\" toName=\"body\" choice=\"multiple\" showInline=\"false\">\n",
        "      <Choice value=\"Credential Harvesting - Fake login page\" />\n",
        "      <Choice value=\"Malware Delivery - Link to download malware\" />\n",
        "      <Choice value=\"Malware Delivery - Malicious Link / Phishing Site\" />\n",
        "      <Choice value=\"Financial Fraud - Gift Card Scam\" />\n",
        "      <Choice value=\"Financial Fraud - BEC (Impersonation/CEO Fraud)\" />\n",
        "      <Choice value=\"Extortion/Blackmail\" />\n",
        "      <Choice value=\"Account Suspension Notice\" />\n",
        "      <Choice value=\"Social Engineering - Romance / Dating Scam\" />\n",
        "      <Choice value=\"Other\" />\n",
        "    </Choices>\n",
        "\n",
        "    <Header value=\"Indicators observed\" size=\"3\" />\n",
        "    <Choices name=\"indicators\" toName=\"body\" choice=\"multiple\" showInline=\"false\">\n",
        "      <Choice value=\"Sender anomalies - Display name spoofing\" />\n",
        "      <Choice value=\"Sender anomalies - Lookalike domain\" />\n",
        "      <Choice value=\"Sender anomalies - Spoofed IP / Email headers indicate fraud\" />\n",
        "      <Choice value=\"Content signals - Urgency/Threats\" />\n",
        "      <Choice value=\"Content signals - Requests money/gift cards\" />\n",
        "      <Choice value=\"Content signals - Poor grammar/spelling\" />\n",
        "      <Choice value=\"Content signals - Unexpected attachment\" />\n",
        "      <Choice value=\"Content signals - Generic greeting (Dear user, etc.)\" />\n",
        "      <Choice value=\"Link issues - Obfuscated/shortened URL\" />\n",
        "      <Choice value=\"Link issues - Domain mismatch with brand\" />\n",
        "      <Choice value=\"Link issues - IP-based URL\" />\n",
        "      <Choice value=\"Other - Request for personal info unrelated to workflow\" />\n",
        "    </Choices>\n",
        "  </View>\n",
        "</View>\n",
        "'''\n",
        "# Creating project in the configured workspace\n",
        "project = ls.projects.create(\n",
        "    title='Phishing Benchmark Tutorial',\n",
        "    workspace=WORKSPACE_ID,\n",
        "    is_published=True,\n",
        "    label_config=label_config\n",
        ")"
      ],
      "metadata": {
        "id": "YQc5wuOFm8wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download emails dataset\n",
        "import pandas as pd\n",
        "DATASET_URL = 'https://gist.githubusercontent.com/mcanu/95507352bfc4557d0ff0430117758abe/raw/eb86433f4c40645d0b1b717877d3468456ab687a/raw_emails.csv'\n",
        "raw_emails = pd.read_csv(DATASET_URL)\n",
        "raw_emails.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5f6BvG4Gng1d",
        "outputId": "c6560ef4-6cb7-4007-a356-8d8e96732e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           raw_email\n",
              "0  Subject: Meeting Confirmation for Project Upda...\n",
              "1  Subject: Invitation to Annual Team Luncheon\\n\\...\n",
              "2  ```\\nFrom: john.doe@example.com\\nTo: jane.smit...\n",
              "3  Subject: Team Meeting Reminder - Thursday at 1...\n",
              "4  Subject: Team Meeting Scheduled for Thursday\\n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1aaa8c2b-b215-4368-989b-4463e34e6cd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_email</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: Meeting Confirmation for Project Upda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: Invitation to Annual Team Luncheon\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>```\\nFrom: john.doe@example.com\\nTo: jane.smit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: Team Meeting Reminder - Thursday at 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: Team Meeting Scheduled for Thursday\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1aaa8c2b-b215-4368-989b-4463e34e6cd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1aaa8c2b-b215-4368-989b-4463e34e6cd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1aaa8c2b-b215-4368-989b-4463e34e6cd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9da7ca89-c40b-468a-a975-3bda9f4c4996\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9da7ca89-c40b-468a-a975-3bda9f4c4996')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9da7ca89-c40b-468a-a975-3bda9f4c4996 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "raw_emails",
              "summary": "{\n  \"name\": \"raw_emails\",\n  \"rows\": 45,\n  \"fields\": [\n    {\n      \"column\": \"raw_email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"```\\nFrom: \\\"Jessica Adams\\\" <updates@digitalworkplacealerts.com>\\nTo: \\\"Emma Clark\\\" <emmaclark@example.com>\\nSubject: Important Update: Company Policy Changes\\n\\nDate: Thu, 19 Oct 2023 11:20:00 +0000\\nMIME-Version: 1.0\\nContent-Type: text/plain; charset=UTF-8\\n\\nDear Emma Clark,\\n\\nWe are reaching out to inform you about recent changes to company policies regarding remote work procedures. It is essential to review these updates to ensure compliance and uninterrupted workflow.\\n\\nTo access the new policy document, please click on the secure link below and log in with your employee credentials:\\n\\n[Review Company Policy](http://digitalworkplace-policy.com/login)\\n\\nFailure to review and acknowledge these changes within the next 24 hours may result in access restrictions to company resources.\\n\\nThank you for your prompt attention to this matter.\\n\\nBest regards,\\n\\nJessica Adams\\nHR Communications\\nDigital Workplace Alerts\\n\\nNote: This is an automated message. Please do not reply. For questions, contact HR through the link above.\\n```\",\n          \"```\\nFrom: Karen Foster <karen.foster@example.com>\\nTo: Lucas Green <lucas.green@example.com>\\nSubject: Invitation to Participate in the Annual Charity Marathon\\n\\nDate: Thu, 21 Oct 2023 10:45:00 -0400\\nMessage-ID: <20231021104500.98321@example.com>\\n\\nHi Lucas,\\n\\nI hope you're doing well! I'm thrilled to invite you to participate in our Annual Charity Marathon taking place on December 5, 2023, at Riverside Park.\\n\\nThis year, we're raising funds for Children's Health Network, and all proceeds will support medical care and research for children in need. Whether you're an experienced runner or just looking for a fun way to contribute to a great cause, we'd love to have you join us.\\n\\nThe marathon will begin at 9:00 AM, and there will be activities and refreshments available for participants and spectators. If you\\u2019re interested, please register by November 15, 2023. Feel free to invite your friends and family!\\n\\nLet me know if you have any questions or need additional details. Looking forward to a wonderful day of community and support.\\n\\nWarm regards,\\nKaren Foster\\nEvent Coordinator at CharityRun Inc.\\nPhone: (234) 590-8765\\nEmail: karen.foster@example.com\\n```\",\n          \"```\\nFrom: Steven Adams <steven.adams@example.com>\\nTo: Megan Ross <megan.ross@example.com>\\nSubject: Update on Supply Chain Optimization Project\\n\\nDate: Fri, 22 Oct 2023 15:30:00 -0400\\nMessage-ID: <20231022153000.11234@example.com>\\n\\nHi Megan,\\n\\nI hope this email finds you well. I'm writing to provide you with the latest updates on our Supply Chain Optimization Project.\\n\\nOur team has made significant progress in streamlining our logistics processes, and we've successfully reduced delivery times by 15% over the past quarter. This improvement is a result of implementing new inventory management software and optimizing our distribution network.\\n\\nAttached, you will find a detailed report highlighting key metrics and the strategies we've employed. As we move forward, we aim to continue these enhancements and explore additional areas for improvement.\\n\\nPlease review the report at your earliest convenience and let me know if you have any feedback or suggestions. Your input has been instrumental in our success thus far.\\n\\nLooking forward to your thoughts.\\n\\nBest regards,\\nSteven Adams\\nSupply Chain Manager at GlobalGoods Inc.\\nPhone: (789) 345-6789\\nEmail: steven.adams@example.com\\n```\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import raw emails as tasks to Label Studio\n",
        "ls.projects.import_tasks(project.id, request=raw_emails.to_dict(orient='records'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k6k2Ydeo_kS",
        "outputId": "aed6b4df-b47c-49a4-881f-d65d34084b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProjectsImportTasksResponse(annotation_count=None, could_be_tasks_list=None, data_columns=None, duration=None, file_upload_ids=None, found_formats=None, predictions_count=None, task_count=None, import=3058032)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Your Benchmark\n",
        "\n",
        "Now, if you go to **Label Studio**, you should see your newly imported tasks in the **Data Manager**.  \n",
        "\n",
        "Click **Label All Tasks** to start labeling your benchmark.  \n",
        "These labeled tasks will serve as your **ground truth** â€” the foundation for evaluating how well different models perform.  \n",
        "\n",
        "*(You can refer to the screenshots below to follow along.)*"
      ],
      "metadata": {
        "id": "QMODAgeFx3A-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://github.com/HumanSignal/awesome-label-studio-tutorials/blob/main/tutorials/how-to-create-benchmark-and-evaluate-your-models/how_to_create_a_Benchmark_and_Evaluate_your_models_with_Label_Studio_files/figure_1.png?raw=true)"
      ],
      "metadata": {
        "id": "Uyf8JJilhPDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set Annotations as Ground Truth\n",
        "\n",
        "Mark your completed annotations as **ground truth**.  \n",
        "This tells Label Studio which annotations to treat as the **source of truth** â€” enabling more accurate and meaningful **agreement metrics** when comparing model predictions against human labels."
      ],
      "metadata": {
        "id": "KZaXytmIyTXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your annotations as ground truth\n",
        "ls.actions.create(id='set_ground_truths', project=project.id, request_options={'additional_body_parameters': {'annotator': user.id}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad7I0IndyMS-",
        "outputId": "0e5555af-608d-470a-dab2-2606e46a8785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Prompts for Model Predictions\n",
        "\n",
        "**Prompts** let you connect and evaluate different AI models directly from Label Studio â€” using a shared prompt template to generate consistent predictions.  \n",
        "\n",
        "Before running evaluations, go to [app.humansignal.com/prompts](https://app.humansignal.com/prompts) and configure the **API keys** for the models you want to test.  \n",
        "You can also add **custom model connections** to evaluate your own or third-party models.  \n",
        "\n",
        "For more details, see the [Prompts configuration guide](https://docs.humansignal.com/guide/prompts_keys).\n",
        "\n",
        "![image](https://github.com/HumanSignal/awesome-label-studio-tutorials/blob/main/tutorials/how-to-create-benchmark-and-evaluate-your-models/how_to_create_a_Benchmark_and_Evaluate_your_models_with_Label_Studio_files/figure_2.png?raw=true)"
      ],
      "metadata": {
        "id": "4mwbPIRIwj4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Run Model Versions with the SDK\n",
        "\n",
        "Next, weâ€™ll use the **Label Studio SDK** to automate the process of model evaluation.  \n",
        "Weâ€™ll create a **prompt** linked to our project, then generate a **model version** for each model we want to test.  \n",
        "\n",
        "Each model version will run inference on **all tasks in the project**, producing **one prediction per model per task** â€” ready for comparison against the ground truth."
      ],
      "metadata": {
        "id": "kTbftyCQzHNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new prompt for our project\n",
        "prompt = ls.prompts.create(\n",
        "    title='Phishing Benchmark Tutorial Prompt',\n",
        "    associated_projects=[project.id],\n",
        "    input_fields=['raw_email'],\n",
        ")"
      ],
      "metadata": {
        "id": "7rrIS4PIwvTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will be testing with 4 models from 2 different providers\n",
        "models = {\n",
        "    'OpenAI': {\n",
        "        'id': None,\n",
        "        'models': ['gpt-5-mini', 'gpt-4.1-mini'],\n",
        "      },\n",
        "    'Gemini': {\n",
        "        'id': None,\n",
        "        'models': ['gemini-2.0-flash-lite', 'gemini-2.5-flash-lite']\n",
        "    }\n",
        "}\n",
        "providers = ls.model_providers.list()\n",
        "\n",
        "# Assign provideer ids to models\n",
        "for provider in providers:\n",
        "    model_info = models.get(provider.provider)\n",
        "    if model_info:\n",
        "      model_info['id'] = provider.id\n",
        "      models[provider.provider] = model_info\n"
      ],
      "metadata": {
        "id": "uoMBBbgRDe2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = '''\n",
        "Analyze the provided email content and classify it as either 'Phishing' or 'Legitimate'.\n",
        "\n",
        "If the email is classified as 'Phishing', identify the specific phishing type(s) and indicators from the options.\n",
        "If the email is legitimate, classify it as 'Legitimate' with no additional phishing type or indicators.\n",
        "\n",
        "Use the following variable in your analysis:\n",
        "\"{raw_email}\"\n",
        "\n",
        "Provide the output in JSON format with the keys:\n",
        "- classification: 'Phishing' or 'Legitimate'\n",
        "- phishing_type: list of strings (if applicable)\n",
        "- indicators: list of strings (if applicable)\n",
        "\n",
        "Ensure the response adheres to the provided JSON schema.\n",
        "'''\n",
        "\n",
        "# Create one prompt version for each model\n",
        "versions = []\n",
        "for provider, info in models.items():\n",
        "    for model_name in info['models']:\n",
        "      version = ls.prompts.versions.create(\n",
        "          prompt_id=prompt.id,\n",
        "          prompt=PROMPT,\n",
        "          provider_model_id=model_name,\n",
        "          title=f'{provider} - {model_name}',\n",
        "          model_provider_connection=info['id'],\n",
        "\n",
        "      )\n",
        "      versions.append(version)\n"
      ],
      "metadata": {
        "id": "GHdYJDo-Auo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference for each version\n",
        "import time\n",
        "\n",
        "# Function to wait for runs to complete\n",
        "def wait_for_runs_to_complete(versions):\n",
        "  completed_versions = []\n",
        "  while len(completed_versions) != len(versions):\n",
        "    for version in versions:\n",
        "      if version in completed_versions:\n",
        "        continue\n",
        "      runs = ls.prompts.runs.list(prompt_id=prompt.id, version_id=version.id)\n",
        "      if runs:\n",
        "        last_run = runs[-1]\n",
        "        if last_run.status == 'Completed':\n",
        "          print('version ', version.id, ' completed')\n",
        "          completed_versions.append(version)\n",
        "    time.sleep(10)\n",
        "\n",
        "# Launch runs for all versions\n",
        "for version in versions:\n",
        "  ls.prompts.runs.create(prompt_id=prompt.id, version_id=version.id, project=project.id, project_subset='All')\n",
        "\n",
        "# Wait for runs to complete\n",
        "wait_for_runs_to_complete(versions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1RAKvRRS92v",
        "outputId": "28d5b9ab-efb8-4566-a330-01b4453e8520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "version  46550  completed\n",
            "version  46551  completed\n",
            "version  46552  completed\n",
            "version  46549  completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project = ls.projects.get(193733)\n",
        "prompt = ls.prompts.get(37050)\n",
        "versions = ls.prompts.versions.list(prompt_id=prompt.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ8YTtOH-r9j",
        "outputId": "7d84d163-af3c-495d-d6c6-d6ffde8f8aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=[], input_type=list])\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=90367, input_type=int])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collect Run Costs\n",
        "\n",
        "Letâ€™s retrieve the **costs for each model run** to include them as additional data points.  \n",
        "Tracking run costs alongside performance metrics helps you understand the **trade-off between accuracy and efficiency** for each model."
      ],
      "metadata": {
        "id": "hpTGqys29Lba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect costs from each run\n",
        "costs = {}\n",
        "for version in versions:\n",
        "  runs = ls.prompts.runs.list(prompt_id=prompt.id, version_id=version.id)\n",
        "  last_run = runs[-1]\n",
        "  cost = ls.prompts.indicators.get(id=last_run.id, indicator_key='inference_cost')\n",
        "  costs[version.title] = {\n",
        "      'Total Cost': cost.values.get('total_cost'),\n",
        "      'Completions Token Count': cost.values.get('completion_tokens_count'),\n",
        "      'Prompt Token Count': cost.values.get('prompt_tokens_count'),\n",
        "  }"
      ],
      "metadata": {
        "id": "r0sJtkuX9euw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Use the existing costs dictionary to create the DataFrame\n",
        "cost_df = pd.DataFrame.from_dict(costs, orient='index')\n",
        "cost_df = cost_df.reset_index().rename(columns={'index': 'Model Version'})\n",
        "\n",
        "display(cost_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "PR4c9IO4CKOy",
        "outputId": "196eefea-3124-41af-9ccd-8b4279499f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    Model Version Total Cost  Completions Token Count  \\\n",
              "0             OpenAI - gpt-5-mini  $0.046268                    18221   \n",
              "1  Gemini - gemini-2.0-flash-lite  $0.003896                     1918   \n",
              "2  Gemini - gemini-2.5-flash-lite  $0.005234                     1934   \n",
              "3           OpenAI - gpt-4.1-mini   $0.01862                     1800   \n",
              "\n",
              "   Prompt Token Count  \n",
              "0               39305  \n",
              "1               44281  \n",
              "2               44606  \n",
              "3               39350  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be3a3019-e2a0-4cb6-8f2e-782e4e10da20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Version</th>\n",
              "      <th>Total Cost</th>\n",
              "      <th>Completions Token Count</th>\n",
              "      <th>Prompt Token Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OpenAI - gpt-5-mini</td>\n",
              "      <td>$0.046268</td>\n",
              "      <td>18221</td>\n",
              "      <td>39305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gemini - gemini-2.0-flash-lite</td>\n",
              "      <td>$0.003896</td>\n",
              "      <td>1918</td>\n",
              "      <td>44281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gemini - gemini-2.5-flash-lite</td>\n",
              "      <td>$0.005234</td>\n",
              "      <td>1934</td>\n",
              "      <td>44606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OpenAI - gpt-4.1-mini</td>\n",
              "      <td>$0.01862</td>\n",
              "      <td>1800</td>\n",
              "      <td>39350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be3a3019-e2a0-4cb6-8f2e-782e4e10da20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be3a3019-e2a0-4cb6-8f2e-782e4e10da20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be3a3019-e2a0-4cb6-8f2e-782e4e10da20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4f7c0adc-8466-41d5-8f0a-a681fcbbe90a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f7c0adc-8466-41d5-8f0a-a681fcbbe90a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4f7c0adc-8466-41d5-8f0a-a681fcbbe90a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c81f023b-c67d-43c4-9908-5b956de43494\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cost_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c81f023b-c67d-43c4-9908-5b956de43494 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cost_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cost_df",
              "summary": "{\n  \"name\": \"cost_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model Version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Gemini - gemini-2.0-flash-lite\",\n          \"OpenAI - gpt-4.1-mini\",\n          \"OpenAI - gpt-5-mini\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Cost\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"$0.003896\",\n          \"$0.01862\",\n          \"$0.046268\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Completions Token Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8168,\n        \"min\": 1800,\n        \"max\": 18221,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1918,\n          1800,\n          18221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt Token Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2956,\n        \"min\": 39305,\n        \"max\": 44606,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          44281,\n          39350,\n          39305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“ˆ Analyze Results\n",
        "\n",
        "Now that all model predictions are complete, we can use the **agreement metrics** provided by Label Studio to measure performance.  \n",
        "\n",
        "Letâ€™s start by looking at the **overall agreement** each model achieved against the ground truth annotations.  \n",
        "This metric shows the **percentage of agreement** between each modelâ€™s predictions and your benchmark labels â€” giving a quick snapshot of model accuracy."
      ],
      "metadata": {
        "id": "1Ml_KIt4zp9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_version_name(prompt, version):\n",
        "  return f'{prompt.title}__{version.title}'\n",
        "\n",
        "\n",
        "gt_agreements = []\n",
        "for version in versions:\n",
        "  version_name = get_version_name(prompt, version)\n",
        "  agreement = ls.projects.stats.model_version_ground_truth_agreement(id=project.id, model_version=version_name)\n",
        "  gt_agreements.append(agreement)"
      ],
      "metadata": {
        "id": "B-3RipMMuSkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "324e2edb",
        "collapsed": true
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'versions' and 'prompt' are available from previous cells\n",
        "version_names = [version.title for version in versions]\n",
        "agreement_values = [item.agreement * 100 for item in gt_agreements]\n",
        "\n",
        "gt_agreement_df = pd.DataFrame({\n",
        "    'Model Version': version_names,\n",
        "    'Agreement (%)': agreement_values\n",
        "})\n",
        "\n",
        "gt_agreement_df = gt_agreement_df.sort_values('Agreement (%)', ascending=False)\n",
        "\n",
        "ax = gt_agreement_df.plot.bar(x='Model Version', y='Agreement (%)', legend=False, rot=45, color=plt.cm.viridis(gt_agreement_df.index / len(gt_agreement_df)))\n",
        "plt.ylabel('Agreement with Ground Truth (%)')\n",
        "plt.xlabel('Model Version')\n",
        "plt.title('Model Version Agreement with Ground Truth (Label Studio Stats)')\n",
        "\n",
        "# Add agreement percentages on top of the bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.1f%%')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agreement per Label\n",
        "\n",
        "Next, letâ€™s explore the **agreement per label** to see how each model performed across different categories.  \n",
        "\n",
        "This view highlights where models **aligned with** or **deviated from** the benchmark â€” both in the main email classification and in the specific **phishing types** and **indicators**.  \n",
        "\n",
        "These insights are extremely valuable for identifying **where models struggle** and **which areas to focus on** when fine-tuning to achieve better results."
      ],
      "metadata": {
        "id": "rDAursP40JLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agreement per label\n",
        "\n",
        "per_label_agreements = []\n",
        "for version in versions:\n",
        "  version_name = get_version_name(prompt, version)\n",
        "  agreement = ls.projects.stats.model_version_ground_truth_agreement(id=project.id, model_version=version_name, per_label=True)\n",
        "  per_label_agreements.append(agreement)"
      ],
      "metadata": {
        "id": "Ct_DPLQ61bd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4aa1344"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "per_label_data = {'Total Cost': {}}\n",
        "for i, version_agreement in enumerate(per_label_agreements):\n",
        "    version_name = versions[i].title\n",
        "    for label, agreement in version_agreement.agreement.items():\n",
        "        if label not in per_label_data:\n",
        "            per_label_data[label] = {}\n",
        "        per_label_data[label][version_name] = agreement * 100 # Convert to percentage\n",
        "    per_label_data['Total Cost'][version_name] = costs[version_name]['Total Cost']\n",
        "\n",
        "per_label_df = pd.DataFrame.from_dict(per_label_data, orient='index')\n",
        "per_label_df = per_label_df.fillna(0) # Fill missing values with 0 if a label doesn't appear for a model\n",
        "\n",
        "# Add color to the table and format percentages, excluding the 'Total Cost' row\n",
        "per_label_df.style.background_gradient(cmap='Pastel1', subset=pd.IndexSlice[per_label_df.index != 'Total Cost', :]).format(\"{:.1f}%\", subset=pd.IndexSlice[per_label_df.index != 'Total Cost', :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŽ¯ Wrapping Up\n",
        "\n",
        "Congrats â€” youâ€™ve just built your own **benchmark** for phishing email classification using **Label Studio**!  \n",
        "\n",
        "With just a few steps, you created a setup that lets you:\n",
        "- ðŸ§  Evaluate how well an LLM classifies phishing vs. legitimate emails  \n",
        "- ðŸ“Š Visualize and compare model outputs in a structured, repeatable way  \n",
        "- ðŸ”„ Build a foundation that can evolve as your models improve  \n",
        "\n",
        "### ðŸ’¡ Why Benchmarks Matter\n",
        "\n",
        "Benchmarks are essential for understanding how your models behave â€” not just whether they â€œwork.â€  \n",
        "They help you:\n",
        "- Identify **strengths and weaknesses** in model reasoning  \n",
        "- Track **progress over time** as your system improves  \n",
        "- Build **trust and transparency** around performance  \n",
        "\n",
        "Benchmarks arenâ€™t static â€” they evolve.  \n",
        "You can continuously expand this benchmark with new examples or categories as your needs grow.\n",
        "\n",
        "### ðŸ§© Why Label Studio\n",
        "\n",
        "Label Studio makes this process simple and collaborative:\n",
        "- Create, manage, and version **custom benchmarks**  \n",
        "- **Evaluate multiple models** on the same dataset  \n",
        "- **Visualize metrics and insights** directly from your labeled data  \n",
        "- Integrate results into your existing ML pipeline for continuous improvement  \n",
        "\n",
        "Thatâ€™s exactly how teams like [*LegalBenchmarks.AI*](https://labelstud.io/blog/how-legalbenchmarks-ai-built-a-domain-specific-ai-benchmark/) build reliable, evolving benchmarks across domains.  \n",
        "\n",
        "### ðŸš€ Next Steps\n",
        "\n",
        "Keep iterating on what you built today:\n",
        "- ðŸ§ª Add more data or expand your label schema  \n",
        "- ðŸ¤– Compare different LLMs or prompt variations  \n",
        "- ðŸ“ˆ Analyze where your model struggles â€” and why  \n",
        "- ðŸ”— Share or automate your evaluation process with your team\n",
        "\n",
        "### ðŸ“š Learn More\n",
        "\n",
        "- [Label Studio Documentation](https://docs.humansignal.com/guide/)  \n",
        "- [Label Studio SDK](https://humansignal.github.io/label-studio-sdk/)  \n",
        "- [Blog: Why Benchmarks Matter for Evaluating LLMs](https://labelstud.io/blog/why-benchmarks-matter-for-evaluating-llms/)  \n",
        "- [Blog: How to Build AI Benchmarks That Evolve with Your Models](https://labelstud.io/blog/how-to-build-ai-benchmarks-that-evolve-with-your-models/)  \n",
        "- [Blog: Evaluating the GPT-5 Series on Custom Benchmarks](https://labelstud.io/blog/evaluating-the-gpt-5-series-on-custom-benchmarks/)  \n",
        "- [Blog: How LegalBenchmarks.AI Built a Domain-Specific AI Benchmark](https://labelstud.io/blog/how-legalbenchmarks-ai-built-a-domain-specific-ai-benchmark/)  "
      ],
      "metadata": {
        "id": "V6ppMctxnumx"
      }
    }
  ]
}